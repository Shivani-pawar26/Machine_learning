{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivani-pawar26/Machine_learning/blob/main/Copy_of_CO_III_Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "CO CST IMPLEMENTATION OF NEURAL NETWORK\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bDN6Un_6rAR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1501a009-ad48-4a31-a70f-e42790960938"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "4a0804f0-727b-4c95-8ce9-bdddb6935966"
      },
      "source": [
        "%cd /content/drive/MyDrive/diabetes.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 20] Not a directory: '/content/drive/MyDrive/diabetes.csv'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9132d5e-af6a-4511-c5f9-a9ac79d448c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "80ca66b3-3c67-4219-e66c-21a2a5f07793"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7303f9ff-7e54-4e87-92d1-286a8c38f74d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7303f9ff-7e54-4e87-92d1-286a8c38f74d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7303f9ff-7e54-4e87-92d1-286a8c38f74d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7303f9ff-7e54-4e87-92d1-286a8c38f74d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "c3d5b845-b77e-42c7-942b-6366baf252b9"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "5ed4c7fa-a40e-4a44-bea0-3c5de0f81e09"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "2b4e32f2-645a-4620-fa02-cfcbd45edbfb"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "92de1c16-65b6-4cd0-8793-cc24281dd6a8"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "5978015f-1a62-4508-f93a-7528d2faf0f5"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "e4584c83-5bf5-49ea-b0b0-247deca2f369"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNfmvbMOXeku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2572be71-add5-41fc-e1f0-d2a3c0346ab4"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(12, activation='tanh'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 24)                216       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                500       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                252       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,090\n",
            "Trainable params: 1,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "54742f0d-b33a-4150-fec2-17bf94235e99"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=750, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.6505 - accuracy: 0.6680 - val_loss: 0.6628 - val_accuracy: 0.6260\n",
            "Epoch 2/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6680 - val_loss: 0.6566 - val_accuracy: 0.6260\n",
            "Epoch 3/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6680 - val_loss: 0.6537 - val_accuracy: 0.6260\n",
            "Epoch 4/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6680 - val_loss: 0.6453 - val_accuracy: 0.6260\n",
            "Epoch 5/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6680 - val_loss: 0.6326 - val_accuracy: 0.6260\n",
            "Epoch 6/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.6680 - val_loss: 0.6192 - val_accuracy: 0.6260\n",
            "Epoch 7/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6680 - val_loss: 0.6230 - val_accuracy: 0.6260\n",
            "Epoch 8/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6680 - val_loss: 0.5938 - val_accuracy: 0.6260\n",
            "Epoch 9/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.6680 - val_loss: 0.5817 - val_accuracy: 0.6260\n",
            "Epoch 10/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.6680 - val_loss: 0.5715 - val_accuracy: 0.6260\n",
            "Epoch 11/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.6823 - val_loss: 0.5536 - val_accuracy: 0.6829\n",
            "Epoch 12/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7189 - val_loss: 0.5441 - val_accuracy: 0.7236\n",
            "Epoch 13/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7352 - val_loss: 0.5695 - val_accuracy: 0.6992\n",
            "Epoch 14/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7373 - val_loss: 0.5389 - val_accuracy: 0.6992\n",
            "Epoch 15/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7617 - val_loss: 0.5195 - val_accuracy: 0.7398\n",
            "Epoch 16/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7454 - val_loss: 0.5268 - val_accuracy: 0.7724\n",
            "Epoch 17/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7475 - val_loss: 0.5124 - val_accuracy: 0.7480\n",
            "Epoch 18/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7393 - val_loss: 0.5093 - val_accuracy: 0.7724\n",
            "Epoch 19/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7678 - val_loss: 0.5549 - val_accuracy: 0.7236\n",
            "Epoch 20/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7576 - val_loss: 0.5113 - val_accuracy: 0.7724\n",
            "Epoch 21/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7637 - val_loss: 0.5279 - val_accuracy: 0.7642\n",
            "Epoch 22/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7658 - val_loss: 0.5003 - val_accuracy: 0.7642\n",
            "Epoch 23/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7515 - val_loss: 0.4999 - val_accuracy: 0.7480\n",
            "Epoch 24/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7495 - val_loss: 0.4926 - val_accuracy: 0.7561\n",
            "Epoch 25/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7617 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 26/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7637 - val_loss: 0.5963 - val_accuracy: 0.7236\n",
            "Epoch 27/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7658 - val_loss: 0.5038 - val_accuracy: 0.7642\n",
            "Epoch 28/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7719 - val_loss: 0.4884 - val_accuracy: 0.7724\n",
            "Epoch 29/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7719 - val_loss: 0.4947 - val_accuracy: 0.7398\n",
            "Epoch 30/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7678 - val_loss: 0.4985 - val_accuracy: 0.7561\n",
            "Epoch 31/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7719 - val_loss: 0.5230 - val_accuracy: 0.7642\n",
            "Epoch 32/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7699 - val_loss: 0.4889 - val_accuracy: 0.7398\n",
            "Epoch 33/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7923 - val_loss: 0.4941 - val_accuracy: 0.7317\n",
            "Epoch 34/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4912 - val_accuracy: 0.7480\n",
            "Epoch 35/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4913 - val_accuracy: 0.7642\n",
            "Epoch 36/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7617 - val_loss: 0.5271 - val_accuracy: 0.7886\n",
            "Epoch 37/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7536 - val_loss: 0.5341 - val_accuracy: 0.7561\n",
            "Epoch 38/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7821 - val_loss: 0.4954 - val_accuracy: 0.7561\n",
            "Epoch 39/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7739 - val_loss: 0.5494 - val_accuracy: 0.7642\n",
            "Epoch 40/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7678 - val_loss: 0.4823 - val_accuracy: 0.7724\n",
            "Epoch 41/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7739 - val_loss: 0.4822 - val_accuracy: 0.7480\n",
            "Epoch 42/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7637 - val_loss: 0.4892 - val_accuracy: 0.7561\n",
            "Epoch 43/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.5522 - val_accuracy: 0.7561\n",
            "Epoch 44/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7719 - val_loss: 0.4906 - val_accuracy: 0.7724\n",
            "Epoch 45/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7678 - val_loss: 0.4845 - val_accuracy: 0.7724\n",
            "Epoch 46/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7800 - val_loss: 0.4903 - val_accuracy: 0.7724\n",
            "Epoch 47/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7780 - val_loss: 0.4982 - val_accuracy: 0.7805\n",
            "Epoch 48/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7821 - val_loss: 0.4937 - val_accuracy: 0.7886\n",
            "Epoch 49/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7719 - val_loss: 0.4820 - val_accuracy: 0.7886\n",
            "Epoch 50/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7800 - val_loss: 0.4891 - val_accuracy: 0.7561\n",
            "Epoch 51/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7862 - val_loss: 0.4793 - val_accuracy: 0.7480\n",
            "Epoch 52/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7886\n",
            "Epoch 53/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7739 - val_loss: 0.5271 - val_accuracy: 0.7805\n",
            "Epoch 54/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7699 - val_loss: 0.4965 - val_accuracy: 0.7561\n",
            "Epoch 55/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7760 - val_loss: 0.4895 - val_accuracy: 0.7480\n",
            "Epoch 56/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4892 - val_accuracy: 0.7886\n",
            "Epoch 57/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5251 - val_accuracy: 0.7480\n",
            "Epoch 58/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7739 - val_loss: 0.4759 - val_accuracy: 0.7967\n",
            "Epoch 59/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7862 - val_loss: 0.4840 - val_accuracy: 0.7724\n",
            "Epoch 60/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7821 - val_loss: 0.4835 - val_accuracy: 0.8049\n",
            "Epoch 61/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7719 - val_loss: 0.4732 - val_accuracy: 0.8049\n",
            "Epoch 62/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.5039 - val_accuracy: 0.7724\n",
            "Epoch 63/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7800 - val_loss: 0.4945 - val_accuracy: 0.7967\n",
            "Epoch 64/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.4867 - val_accuracy: 0.7724\n",
            "Epoch 65/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7637 - val_loss: 0.4829 - val_accuracy: 0.7886\n",
            "Epoch 66/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7800 - val_loss: 0.5051 - val_accuracy: 0.7561\n",
            "Epoch 67/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7841 - val_loss: 0.4828 - val_accuracy: 0.7886\n",
            "Epoch 68/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7841 - val_loss: 0.4826 - val_accuracy: 0.7724\n",
            "Epoch 69/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7886\n",
            "Epoch 70/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8004 - val_loss: 0.4923 - val_accuracy: 0.7805\n",
            "Epoch 71/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7841 - val_loss: 0.4738 - val_accuracy: 0.7805\n",
            "Epoch 72/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7780 - val_loss: 0.4783 - val_accuracy: 0.7642\n",
            "Epoch 73/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7923 - val_loss: 0.4748 - val_accuracy: 0.8049\n",
            "Epoch 74/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5045 - val_accuracy: 0.7967\n",
            "Epoch 75/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.5625 - val_accuracy: 0.6992\n",
            "Epoch 76/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7658 - val_loss: 0.4833 - val_accuracy: 0.7561\n",
            "Epoch 77/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7719 - val_loss: 0.4710 - val_accuracy: 0.7724\n",
            "Epoch 78/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7739 - val_loss: 0.5134 - val_accuracy: 0.7967\n",
            "Epoch 79/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7841 - val_loss: 0.4822 - val_accuracy: 0.7886\n",
            "Epoch 80/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8004 - val_loss: 0.4812 - val_accuracy: 0.7724\n",
            "Epoch 81/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7841 - val_loss: 0.4768 - val_accuracy: 0.8049\n",
            "Epoch 82/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7821 - val_loss: 0.4705 - val_accuracy: 0.7967\n",
            "Epoch 83/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7923 - val_loss: 0.5029 - val_accuracy: 0.7642\n",
            "Epoch 84/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7923 - val_loss: 0.5263 - val_accuracy: 0.7317\n",
            "Epoch 85/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7841 - val_loss: 0.4713 - val_accuracy: 0.7724\n",
            "Epoch 86/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7841 - val_loss: 0.4694 - val_accuracy: 0.7805\n",
            "Epoch 87/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7780 - val_loss: 0.4875 - val_accuracy: 0.7642\n",
            "Epoch 88/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7902 - val_loss: 0.4809 - val_accuracy: 0.7805\n",
            "Epoch 89/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7821 - val_loss: 0.4777 - val_accuracy: 0.7805\n",
            "Epoch 90/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
            "Epoch 91/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7642\n",
            "Epoch 92/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7800 - val_loss: 0.4802 - val_accuracy: 0.7886\n",
            "Epoch 93/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7902 - val_loss: 0.4777 - val_accuracy: 0.7724\n",
            "Epoch 94/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.4935 - val_accuracy: 0.7724\n",
            "Epoch 95/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7841 - val_loss: 0.5282 - val_accuracy: 0.7642\n",
            "Epoch 96/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7699 - val_loss: 0.4734 - val_accuracy: 0.7805\n",
            "Epoch 97/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7923 - val_loss: 0.4882 - val_accuracy: 0.7724\n",
            "Epoch 98/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7821 - val_loss: 0.4798 - val_accuracy: 0.7724\n",
            "Epoch 99/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7886\n",
            "Epoch 100/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7800 - val_loss: 0.5539 - val_accuracy: 0.7642\n",
            "Epoch 101/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7963 - val_loss: 0.4894 - val_accuracy: 0.7642\n",
            "Epoch 102/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7480\n",
            "Epoch 103/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7719 - val_loss: 0.4886 - val_accuracy: 0.7642\n",
            "Epoch 104/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7963 - val_loss: 0.4800 - val_accuracy: 0.7724\n",
            "Epoch 105/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7943 - val_loss: 0.4864 - val_accuracy: 0.7561\n",
            "Epoch 106/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7902 - val_loss: 0.5044 - val_accuracy: 0.7967\n",
            "Epoch 107/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7902 - val_loss: 0.4980 - val_accuracy: 0.7561\n",
            "Epoch 108/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7902 - val_loss: 0.4825 - val_accuracy: 0.7724\n",
            "Epoch 109/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8024 - val_loss: 0.4751 - val_accuracy: 0.8049\n",
            "Epoch 110/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7943 - val_loss: 0.4772 - val_accuracy: 0.7805\n",
            "Epoch 111/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7821 - val_loss: 0.4818 - val_accuracy: 0.7642\n",
            "Epoch 112/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7923 - val_loss: 0.4766 - val_accuracy: 0.7724\n",
            "Epoch 113/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8065 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 114/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7739 - val_loss: 0.4755 - val_accuracy: 0.7724\n",
            "Epoch 115/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7902 - val_loss: 0.5030 - val_accuracy: 0.7967\n",
            "Epoch 116/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7780 - val_loss: 0.4767 - val_accuracy: 0.7642\n",
            "Epoch 117/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7841 - val_loss: 0.5032 - val_accuracy: 0.7805\n",
            "Epoch 118/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7923 - val_loss: 0.5368 - val_accuracy: 0.7805\n",
            "Epoch 119/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7862 - val_loss: 0.4924 - val_accuracy: 0.7724\n",
            "Epoch 120/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7561\n",
            "Epoch 121/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8045 - val_loss: 0.4697 - val_accuracy: 0.7724\n",
            "Epoch 122/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7943 - val_loss: 0.4807 - val_accuracy: 0.7967\n",
            "Epoch 123/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7739 - val_loss: 0.5097 - val_accuracy: 0.7967\n",
            "Epoch 124/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.4823 - val_accuracy: 0.7724\n",
            "Epoch 125/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7862 - val_loss: 0.4927 - val_accuracy: 0.7561\n",
            "Epoch 126/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7902 - val_loss: 0.4903 - val_accuracy: 0.7642\n",
            "Epoch 127/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7760 - val_loss: 0.4826 - val_accuracy: 0.7724\n",
            "Epoch 128/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7841 - val_loss: 0.4763 - val_accuracy: 0.7805\n",
            "Epoch 129/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7841 - val_loss: 0.5221 - val_accuracy: 0.7886\n",
            "Epoch 130/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8004 - val_loss: 0.4811 - val_accuracy: 0.7561\n",
            "Epoch 131/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7821 - val_loss: 0.4971 - val_accuracy: 0.7642\n",
            "Epoch 132/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7943 - val_loss: 0.4970 - val_accuracy: 0.7561\n",
            "Epoch 133/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7841 - val_loss: 0.5235 - val_accuracy: 0.7724\n",
            "Epoch 134/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8004 - val_loss: 0.5047 - val_accuracy: 0.7642\n",
            "Epoch 135/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7963 - val_loss: 0.4945 - val_accuracy: 0.7724\n",
            "Epoch 136/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7800 - val_loss: 0.4745 - val_accuracy: 0.7724\n",
            "Epoch 137/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7943 - val_loss: 0.5244 - val_accuracy: 0.7561\n",
            "Epoch 138/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7699 - val_loss: 0.4930 - val_accuracy: 0.7561\n",
            "Epoch 139/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7800 - val_loss: 0.4900 - val_accuracy: 0.7642\n",
            "Epoch 140/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7800 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 141/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7943 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 142/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7800 - val_loss: 0.5190 - val_accuracy: 0.7724\n",
            "Epoch 143/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8065 - val_loss: 0.4789 - val_accuracy: 0.7724\n",
            "Epoch 144/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7862 - val_loss: 0.4804 - val_accuracy: 0.7805\n",
            "Epoch 145/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7862 - val_loss: 0.4819 - val_accuracy: 0.7642\n",
            "Epoch 146/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7800 - val_loss: 0.5129 - val_accuracy: 0.7561\n",
            "Epoch 147/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7923 - val_loss: 0.5241 - val_accuracy: 0.7724\n",
            "Epoch 148/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8045 - val_loss: 0.5039 - val_accuracy: 0.7642\n",
            "Epoch 149/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8024 - val_loss: 0.5022 - val_accuracy: 0.7561\n",
            "Epoch 150/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7724\n",
            "Epoch 151/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7943 - val_loss: 0.4960 - val_accuracy: 0.7642\n",
            "Epoch 152/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7963 - val_loss: 0.4984 - val_accuracy: 0.7561\n",
            "Epoch 153/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7902 - val_loss: 0.5453 - val_accuracy: 0.7967\n",
            "Epoch 154/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7963 - val_loss: 0.4962 - val_accuracy: 0.7886\n",
            "Epoch 155/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8024 - val_loss: 0.6239 - val_accuracy: 0.7724\n",
            "Epoch 156/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7923 - val_loss: 0.4963 - val_accuracy: 0.7724\n",
            "Epoch 157/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7984 - val_loss: 0.5020 - val_accuracy: 0.7724\n",
            "Epoch 158/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7943 - val_loss: 0.5123 - val_accuracy: 0.7561\n",
            "Epoch 159/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7821 - val_loss: 0.5101 - val_accuracy: 0.7480\n",
            "Epoch 160/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8065 - val_loss: 0.5174 - val_accuracy: 0.7317\n",
            "Epoch 161/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8004 - val_loss: 0.5140 - val_accuracy: 0.7724\n",
            "Epoch 162/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7943 - val_loss: 0.4859 - val_accuracy: 0.7886\n",
            "Epoch 163/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8086 - val_loss: 0.4959 - val_accuracy: 0.7642\n",
            "Epoch 164/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8004 - val_loss: 0.5117 - val_accuracy: 0.7561\n",
            "Epoch 165/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7800 - val_loss: 0.4842 - val_accuracy: 0.7886\n",
            "Epoch 166/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8004 - val_loss: 0.4913 - val_accuracy: 0.7642\n",
            "Epoch 167/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7841 - val_loss: 0.5204 - val_accuracy: 0.7724\n",
            "Epoch 168/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8086 - val_loss: 0.5058 - val_accuracy: 0.7805\n",
            "Epoch 169/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8065 - val_loss: 0.4966 - val_accuracy: 0.7724\n",
            "Epoch 170/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7943 - val_loss: 0.5232 - val_accuracy: 0.7561\n",
            "Epoch 171/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.7963 - val_loss: 0.5093 - val_accuracy: 0.7724\n",
            "Epoch 172/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8024 - val_loss: 0.5304 - val_accuracy: 0.7480\n",
            "Epoch 173/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8106 - val_loss: 0.5264 - val_accuracy: 0.7642\n",
            "Epoch 174/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8004 - val_loss: 0.4872 - val_accuracy: 0.7967\n",
            "Epoch 175/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8004 - val_loss: 0.4942 - val_accuracy: 0.7805\n",
            "Epoch 176/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8045 - val_loss: 0.5156 - val_accuracy: 0.7480\n",
            "Epoch 177/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8106 - val_loss: 0.5477 - val_accuracy: 0.7480\n",
            "Epoch 178/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 179/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8004 - val_loss: 0.4962 - val_accuracy: 0.7724\n",
            "Epoch 180/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8045 - val_loss: 0.5018 - val_accuracy: 0.7886\n",
            "Epoch 181/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7780 - val_loss: 0.5238 - val_accuracy: 0.7642\n",
            "Epoch 182/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8187 - val_loss: 0.5360 - val_accuracy: 0.7480\n",
            "Epoch 183/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8004 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 184/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7862 - val_loss: 0.5009 - val_accuracy: 0.7724\n",
            "Epoch 185/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8065 - val_loss: 0.5126 - val_accuracy: 0.7642\n",
            "Epoch 186/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8147 - val_loss: 0.5111 - val_accuracy: 0.7805\n",
            "Epoch 187/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8024 - val_loss: 0.5420 - val_accuracy: 0.7642\n",
            "Epoch 188/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8024 - val_loss: 0.5262 - val_accuracy: 0.7724\n",
            "Epoch 189/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8065 - val_loss: 0.5626 - val_accuracy: 0.7561\n",
            "Epoch 190/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8086 - val_loss: 0.5607 - val_accuracy: 0.7886\n",
            "Epoch 191/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.7963 - val_loss: 0.6225 - val_accuracy: 0.7642\n",
            "Epoch 192/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8167 - val_loss: 0.5584 - val_accuracy: 0.7805\n",
            "Epoch 193/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8024 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
            "Epoch 194/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8024 - val_loss: 0.6609 - val_accuracy: 0.7724\n",
            "Epoch 195/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8024 - val_loss: 0.4972 - val_accuracy: 0.7724\n",
            "Epoch 196/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.7984 - val_loss: 0.5337 - val_accuracy: 0.7480\n",
            "Epoch 197/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8086 - val_loss: 0.5114 - val_accuracy: 0.7805\n",
            "Epoch 198/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8024 - val_loss: 0.5251 - val_accuracy: 0.7480\n",
            "Epoch 199/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7805\n",
            "Epoch 200/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.7963 - val_loss: 0.5094 - val_accuracy: 0.7886\n",
            "Epoch 201/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8086 - val_loss: 0.5112 - val_accuracy: 0.7642\n",
            "Epoch 202/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8024 - val_loss: 0.5102 - val_accuracy: 0.7724\n",
            "Epoch 203/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8126 - val_loss: 0.5096 - val_accuracy: 0.7642\n",
            "Epoch 204/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8086 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 205/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8147 - val_loss: 0.5346 - val_accuracy: 0.7724\n",
            "Epoch 206/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.7963 - val_loss: 0.5282 - val_accuracy: 0.7642\n",
            "Epoch 207/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8147 - val_loss: 0.5223 - val_accuracy: 0.7642\n",
            "Epoch 208/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8045 - val_loss: 0.5118 - val_accuracy: 0.7724\n",
            "Epoch 209/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.7841 - val_loss: 0.6256 - val_accuracy: 0.7724\n",
            "Epoch 210/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8106 - val_loss: 0.5271 - val_accuracy: 0.7642\n",
            "Epoch 211/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8106 - val_loss: 0.5278 - val_accuracy: 0.7642\n",
            "Epoch 212/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8126 - val_loss: 0.5418 - val_accuracy: 0.7642\n",
            "Epoch 213/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8024 - val_loss: 0.5421 - val_accuracy: 0.7724\n",
            "Epoch 214/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8126 - val_loss: 0.4982 - val_accuracy: 0.7967\n",
            "Epoch 215/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8086 - val_loss: 0.6248 - val_accuracy: 0.7480\n",
            "Epoch 216/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8086 - val_loss: 0.6293 - val_accuracy: 0.7561\n",
            "Epoch 217/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.7882 - val_loss: 0.6394 - val_accuracy: 0.7886\n",
            "Epoch 218/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.7923 - val_loss: 0.5035 - val_accuracy: 0.7886\n",
            "Epoch 219/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8106 - val_loss: 0.5179 - val_accuracy: 0.7642\n",
            "Epoch 220/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8086 - val_loss: 0.5406 - val_accuracy: 0.7480\n",
            "Epoch 221/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8147 - val_loss: 0.5703 - val_accuracy: 0.7724\n",
            "Epoch 222/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8208 - val_loss: 0.5170 - val_accuracy: 0.7724\n",
            "Epoch 223/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8024 - val_loss: 0.5118 - val_accuracy: 0.7642\n",
            "Epoch 224/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8065 - val_loss: 0.5290 - val_accuracy: 0.7561\n",
            "Epoch 225/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.7882 - val_loss: 0.5787 - val_accuracy: 0.7480\n",
            "Epoch 226/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.7984 - val_loss: 0.5322 - val_accuracy: 0.7967\n",
            "Epoch 227/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.7984 - val_loss: 0.5706 - val_accuracy: 0.8049\n",
            "Epoch 228/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8126 - val_loss: 0.5790 - val_accuracy: 0.7561\n",
            "Epoch 229/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.7943 - val_loss: 0.5106 - val_accuracy: 0.7805\n",
            "Epoch 230/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8065 - val_loss: 0.5850 - val_accuracy: 0.6992\n",
            "Epoch 231/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8167 - val_loss: 0.5648 - val_accuracy: 0.7398\n",
            "Epoch 232/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8167 - val_loss: 0.5371 - val_accuracy: 0.7642\n",
            "Epoch 233/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8045 - val_loss: 0.5545 - val_accuracy: 0.7561\n",
            "Epoch 234/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8208 - val_loss: 0.5837 - val_accuracy: 0.7073\n",
            "Epoch 235/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8310 - val_loss: 0.5513 - val_accuracy: 0.7398\n",
            "Epoch 236/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.7963 - val_loss: 0.5251 - val_accuracy: 0.7805\n",
            "Epoch 237/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8126 - val_loss: 0.5707 - val_accuracy: 0.7480\n",
            "Epoch 238/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8187 - val_loss: 0.5389 - val_accuracy: 0.7398\n",
            "Epoch 239/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.7984 - val_loss: 0.5321 - val_accuracy: 0.7642\n",
            "Epoch 240/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8167 - val_loss: 0.5182 - val_accuracy: 0.7805\n",
            "Epoch 241/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8004 - val_loss: 0.5119 - val_accuracy: 0.8049\n",
            "Epoch 242/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8350 - val_loss: 0.6538 - val_accuracy: 0.7317\n",
            "Epoch 243/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8269 - val_loss: 0.5510 - val_accuracy: 0.7561\n",
            "Epoch 244/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8045 - val_loss: 0.5417 - val_accuracy: 0.7642\n",
            "Epoch 245/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8187 - val_loss: 0.5913 - val_accuracy: 0.7480\n",
            "Epoch 246/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8187 - val_loss: 0.5354 - val_accuracy: 0.7724\n",
            "Epoch 247/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8167 - val_loss: 0.5190 - val_accuracy: 0.7724\n",
            "Epoch 248/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8126 - val_loss: 0.5537 - val_accuracy: 0.7642\n",
            "Epoch 249/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8086 - val_loss: 0.5153 - val_accuracy: 0.7886\n",
            "Epoch 250/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8167 - val_loss: 0.5344 - val_accuracy: 0.7724\n",
            "Epoch 251/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8147 - val_loss: 0.5717 - val_accuracy: 0.7642\n",
            "Epoch 252/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8086 - val_loss: 0.5376 - val_accuracy: 0.7805\n",
            "Epoch 253/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8167 - val_loss: 0.5429 - val_accuracy: 0.7805\n",
            "Epoch 254/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8086 - val_loss: 0.5346 - val_accuracy: 0.7805\n",
            "Epoch 255/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8350 - val_loss: 0.5452 - val_accuracy: 0.7724\n",
            "Epoch 256/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8024 - val_loss: 0.5535 - val_accuracy: 0.7886\n",
            "Epoch 257/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8126 - val_loss: 0.5697 - val_accuracy: 0.7561\n",
            "Epoch 258/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8045 - val_loss: 0.5646 - val_accuracy: 0.7724\n",
            "Epoch 259/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8187 - val_loss: 0.5562 - val_accuracy: 0.7886\n",
            "Epoch 260/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8167 - val_loss: 0.5400 - val_accuracy: 0.7967\n",
            "Epoch 261/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8289 - val_loss: 0.6245 - val_accuracy: 0.7480\n",
            "Epoch 262/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8147 - val_loss: 0.5562 - val_accuracy: 0.7642\n",
            "Epoch 263/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8248 - val_loss: 0.6000 - val_accuracy: 0.7561\n",
            "Epoch 264/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8187 - val_loss: 0.5616 - val_accuracy: 0.7480\n",
            "Epoch 265/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8330 - val_loss: 0.6086 - val_accuracy: 0.7398\n",
            "Epoch 266/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8289 - val_loss: 0.6274 - val_accuracy: 0.7398\n",
            "Epoch 267/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8106 - val_loss: 0.5919 - val_accuracy: 0.7561\n",
            "Epoch 268/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8228 - val_loss: 0.5852 - val_accuracy: 0.7398\n",
            "Epoch 269/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8086 - val_loss: 0.5568 - val_accuracy: 0.7724\n",
            "Epoch 270/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8208 - val_loss: 0.5506 - val_accuracy: 0.7642\n",
            "Epoch 271/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8248 - val_loss: 0.6078 - val_accuracy: 0.7236\n",
            "Epoch 272/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8126 - val_loss: 0.6009 - val_accuracy: 0.7886\n",
            "Epoch 273/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8208 - val_loss: 0.5938 - val_accuracy: 0.7236\n",
            "Epoch 274/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8228 - val_loss: 0.6576 - val_accuracy: 0.7398\n",
            "Epoch 275/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8106 - val_loss: 0.5962 - val_accuracy: 0.7561\n",
            "Epoch 276/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8391 - val_loss: 0.5464 - val_accuracy: 0.7805\n",
            "Epoch 277/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8289 - val_loss: 0.5759 - val_accuracy: 0.7154\n",
            "Epoch 278/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8126 - val_loss: 0.5904 - val_accuracy: 0.7805\n",
            "Epoch 279/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8269 - val_loss: 0.5595 - val_accuracy: 0.7642\n",
            "Epoch 280/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8187 - val_loss: 0.5691 - val_accuracy: 0.7642\n",
            "Epoch 281/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8167 - val_loss: 0.5900 - val_accuracy: 0.7805\n",
            "Epoch 282/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8269 - val_loss: 0.5743 - val_accuracy: 0.7561\n",
            "Epoch 283/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8330 - val_loss: 0.5607 - val_accuracy: 0.7561\n",
            "Epoch 284/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8147 - val_loss: 0.5671 - val_accuracy: 0.7561\n",
            "Epoch 285/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8269 - val_loss: 0.6546 - val_accuracy: 0.7236\n",
            "Epoch 286/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8350 - val_loss: 0.5581 - val_accuracy: 0.7561\n",
            "Epoch 287/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8391 - val_loss: 0.6395 - val_accuracy: 0.7317\n",
            "Epoch 288/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8371 - val_loss: 0.6028 - val_accuracy: 0.7398\n",
            "Epoch 289/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8147 - val_loss: 0.6015 - val_accuracy: 0.7561\n",
            "Epoch 290/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8228 - val_loss: 0.5589 - val_accuracy: 0.7886\n",
            "Epoch 291/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8045 - val_loss: 0.5610 - val_accuracy: 0.7642\n",
            "Epoch 292/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8330 - val_loss: 0.5805 - val_accuracy: 0.7642\n",
            "Epoch 293/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8106 - val_loss: 0.5615 - val_accuracy: 0.7724\n",
            "Epoch 294/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8330 - val_loss: 0.5968 - val_accuracy: 0.7561\n",
            "Epoch 295/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8187 - val_loss: 0.6040 - val_accuracy: 0.7724\n",
            "Epoch 296/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8248 - val_loss: 0.5704 - val_accuracy: 0.7724\n",
            "Epoch 297/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8147 - val_loss: 0.5754 - val_accuracy: 0.7724\n",
            "Epoch 298/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8106 - val_loss: 0.6380 - val_accuracy: 0.7480\n",
            "Epoch 299/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8371 - val_loss: 0.6469 - val_accuracy: 0.7398\n",
            "Epoch 300/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8228 - val_loss: 0.6029 - val_accuracy: 0.7398\n",
            "Epoch 301/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8248 - val_loss: 0.5882 - val_accuracy: 0.7154\n",
            "Epoch 302/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8391 - val_loss: 0.5865 - val_accuracy: 0.7480\n",
            "Epoch 303/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8391 - val_loss: 0.5865 - val_accuracy: 0.7561\n",
            "Epoch 304/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8248 - val_loss: 0.6021 - val_accuracy: 0.7561\n",
            "Epoch 305/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8248 - val_loss: 0.5789 - val_accuracy: 0.7967\n",
            "Epoch 306/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8289 - val_loss: 0.6252 - val_accuracy: 0.7480\n",
            "Epoch 307/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8289 - val_loss: 0.5819 - val_accuracy: 0.7561\n",
            "Epoch 308/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8187 - val_loss: 0.6415 - val_accuracy: 0.7398\n",
            "Epoch 309/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8269 - val_loss: 0.5893 - val_accuracy: 0.7398\n",
            "Epoch 310/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8187 - val_loss: 0.6268 - val_accuracy: 0.7073\n",
            "Epoch 311/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8147 - val_loss: 0.5857 - val_accuracy: 0.7805\n",
            "Epoch 312/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8289 - val_loss: 0.6237 - val_accuracy: 0.7317\n",
            "Epoch 313/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8432 - val_loss: 0.6096 - val_accuracy: 0.7398\n",
            "Epoch 314/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8289 - val_loss: 0.5724 - val_accuracy: 0.7886\n",
            "Epoch 315/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8269 - val_loss: 0.5832 - val_accuracy: 0.7642\n",
            "Epoch 316/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8330 - val_loss: 0.5970 - val_accuracy: 0.7236\n",
            "Epoch 317/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8269 - val_loss: 0.7669 - val_accuracy: 0.6016\n",
            "Epoch 318/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8126 - val_loss: 0.6256 - val_accuracy: 0.7561\n",
            "Epoch 319/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8208 - val_loss: 0.5674 - val_accuracy: 0.7642\n",
            "Epoch 320/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8330 - val_loss: 0.6111 - val_accuracy: 0.7561\n",
            "Epoch 321/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8269 - val_loss: 0.6320 - val_accuracy: 0.7398\n",
            "Epoch 322/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8432 - val_loss: 0.5905 - val_accuracy: 0.7561\n",
            "Epoch 323/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8269 - val_loss: 0.5951 - val_accuracy: 0.7480\n",
            "Epoch 324/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8228 - val_loss: 0.6430 - val_accuracy: 0.7398\n",
            "Epoch 325/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8371 - val_loss: 0.6112 - val_accuracy: 0.7724\n",
            "Epoch 326/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8391 - val_loss: 0.6262 - val_accuracy: 0.7317\n",
            "Epoch 327/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8208 - val_loss: 0.6638 - val_accuracy: 0.7561\n",
            "Epoch 328/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8350 - val_loss: 0.5918 - val_accuracy: 0.7886\n",
            "Epoch 329/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8289 - val_loss: 0.6364 - val_accuracy: 0.7480\n",
            "Epoch 330/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8330 - val_loss: 0.5656 - val_accuracy: 0.7724\n",
            "Epoch 331/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8371 - val_loss: 0.6473 - val_accuracy: 0.7561\n",
            "Epoch 332/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8350 - val_loss: 0.6071 - val_accuracy: 0.7724\n",
            "Epoch 333/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8350 - val_loss: 0.6159 - val_accuracy: 0.7724\n",
            "Epoch 334/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8310 - val_loss: 0.6314 - val_accuracy: 0.7317\n",
            "Epoch 335/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8432 - val_loss: 0.6211 - val_accuracy: 0.7317\n",
            "Epoch 336/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8350 - val_loss: 0.6935 - val_accuracy: 0.7642\n",
            "Epoch 337/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8269 - val_loss: 0.5984 - val_accuracy: 0.7642\n",
            "Epoch 338/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8289 - val_loss: 0.5704 - val_accuracy: 0.7561\n",
            "Epoch 339/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8289 - val_loss: 0.6241 - val_accuracy: 0.7561\n",
            "Epoch 340/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8371 - val_loss: 0.6384 - val_accuracy: 0.7561\n",
            "Epoch 341/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8371 - val_loss: 0.5812 - val_accuracy: 0.7724\n",
            "Epoch 342/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8310 - val_loss: 0.7057 - val_accuracy: 0.7317\n",
            "Epoch 343/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8432 - val_loss: 0.5961 - val_accuracy: 0.7805\n",
            "Epoch 344/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8371 - val_loss: 0.6787 - val_accuracy: 0.7398\n",
            "Epoch 345/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8289 - val_loss: 0.5912 - val_accuracy: 0.7317\n",
            "Epoch 346/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8248 - val_loss: 0.6611 - val_accuracy: 0.7073\n",
            "Epoch 347/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8330 - val_loss: 0.6018 - val_accuracy: 0.7561\n",
            "Epoch 348/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8432 - val_loss: 0.7017 - val_accuracy: 0.7317\n",
            "Epoch 349/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8391 - val_loss: 0.6440 - val_accuracy: 0.7561\n",
            "Epoch 350/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8330 - val_loss: 0.6060 - val_accuracy: 0.7480\n",
            "Epoch 351/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8432 - val_loss: 0.6038 - val_accuracy: 0.7805\n",
            "Epoch 352/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8269 - val_loss: 0.6250 - val_accuracy: 0.7805\n",
            "Epoch 353/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8452 - val_loss: 0.5937 - val_accuracy: 0.7805\n",
            "Epoch 354/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8350 - val_loss: 0.6719 - val_accuracy: 0.6992\n",
            "Epoch 355/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8330 - val_loss: 0.6250 - val_accuracy: 0.7398\n",
            "Epoch 356/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8513 - val_loss: 0.6787 - val_accuracy: 0.7073\n",
            "Epoch 357/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8310 - val_loss: 0.6332 - val_accuracy: 0.7480\n",
            "Epoch 358/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8269 - val_loss: 0.7032 - val_accuracy: 0.6585\n",
            "Epoch 359/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8391 - val_loss: 0.6434 - val_accuracy: 0.7642\n",
            "Epoch 360/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8371 - val_loss: 0.6040 - val_accuracy: 0.7724\n",
            "Epoch 361/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8411 - val_loss: 0.7137 - val_accuracy: 0.7236\n",
            "Epoch 362/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8310 - val_loss: 0.7678 - val_accuracy: 0.7480\n",
            "Epoch 363/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8330 - val_loss: 0.7055 - val_accuracy: 0.7236\n",
            "Epoch 364/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8350 - val_loss: 0.6394 - val_accuracy: 0.7398\n",
            "Epoch 365/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8310 - val_loss: 0.6433 - val_accuracy: 0.6911\n",
            "Epoch 366/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8350 - val_loss: 0.6574 - val_accuracy: 0.7236\n",
            "Epoch 367/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8350 - val_loss: 0.6458 - val_accuracy: 0.7073\n",
            "Epoch 368/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8493 - val_loss: 0.6578 - val_accuracy: 0.7480\n",
            "Epoch 369/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8432 - val_loss: 0.6620 - val_accuracy: 0.7398\n",
            "Epoch 370/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8391 - val_loss: 0.6503 - val_accuracy: 0.7724\n",
            "Epoch 371/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8371 - val_loss: 0.6266 - val_accuracy: 0.7480\n",
            "Epoch 372/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8350 - val_loss: 0.7233 - val_accuracy: 0.7561\n",
            "Epoch 373/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8391 - val_loss: 0.6217 - val_accuracy: 0.7236\n",
            "Epoch 374/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8432 - val_loss: 0.6682 - val_accuracy: 0.7317\n",
            "Epoch 375/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8228 - val_loss: 0.6380 - val_accuracy: 0.7724\n",
            "Epoch 376/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8391 - val_loss: 0.6823 - val_accuracy: 0.6992\n",
            "Epoch 377/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8513 - val_loss: 0.6845 - val_accuracy: 0.7317\n",
            "Epoch 378/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8350 - val_loss: 0.6869 - val_accuracy: 0.6992\n",
            "Epoch 379/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8289 - val_loss: 0.6379 - val_accuracy: 0.7480\n",
            "Epoch 380/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8635 - val_loss: 0.6582 - val_accuracy: 0.7317\n",
            "Epoch 381/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8371 - val_loss: 0.6343 - val_accuracy: 0.7561\n",
            "Epoch 382/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8391 - val_loss: 0.6515 - val_accuracy: 0.7398\n",
            "Epoch 383/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8371 - val_loss: 0.6229 - val_accuracy: 0.7561\n",
            "Epoch 384/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8473 - val_loss: 0.6513 - val_accuracy: 0.7480\n",
            "Epoch 385/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8350 - val_loss: 0.6366 - val_accuracy: 0.7642\n",
            "Epoch 386/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8310 - val_loss: 0.7078 - val_accuracy: 0.7236\n",
            "Epoch 387/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8391 - val_loss: 0.7392 - val_accuracy: 0.7236\n",
            "Epoch 388/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8432 - val_loss: 0.6669 - val_accuracy: 0.7480\n",
            "Epoch 389/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8473 - val_loss: 0.6509 - val_accuracy: 0.7480\n",
            "Epoch 390/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8432 - val_loss: 0.7118 - val_accuracy: 0.7073\n",
            "Epoch 391/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8635 - val_loss: 0.6539 - val_accuracy: 0.7236\n",
            "Epoch 392/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8411 - val_loss: 0.7015 - val_accuracy: 0.7317\n",
            "Epoch 393/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8371 - val_loss: 0.7024 - val_accuracy: 0.7236\n",
            "Epoch 394/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8452 - val_loss: 0.6675 - val_accuracy: 0.7561\n",
            "Epoch 395/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8452 - val_loss: 0.6802 - val_accuracy: 0.7480\n",
            "Epoch 396/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8269 - val_loss: 0.7027 - val_accuracy: 0.7317\n",
            "Epoch 397/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8473 - val_loss: 0.7074 - val_accuracy: 0.7317\n",
            "Epoch 398/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8493 - val_loss: 0.7087 - val_accuracy: 0.7154\n",
            "Epoch 399/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8493 - val_loss: 0.6875 - val_accuracy: 0.7236\n",
            "Epoch 400/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8595 - val_loss: 0.7127 - val_accuracy: 0.7561\n",
            "Epoch 401/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8350 - val_loss: 0.7201 - val_accuracy: 0.7236\n",
            "Epoch 402/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8534 - val_loss: 0.7038 - val_accuracy: 0.7154\n",
            "Epoch 403/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8432 - val_loss: 0.6634 - val_accuracy: 0.7480\n",
            "Epoch 404/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8391 - val_loss: 0.6623 - val_accuracy: 0.7642\n",
            "Epoch 405/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8371 - val_loss: 0.7044 - val_accuracy: 0.7236\n",
            "Epoch 406/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8574 - val_loss: 0.7100 - val_accuracy: 0.7154\n",
            "Epoch 407/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8371 - val_loss: 0.6685 - val_accuracy: 0.7236\n",
            "Epoch 408/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8432 - val_loss: 0.6807 - val_accuracy: 0.7398\n",
            "Epoch 409/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8432 - val_loss: 0.7347 - val_accuracy: 0.7154\n",
            "Epoch 410/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8371 - val_loss: 0.6730 - val_accuracy: 0.7480\n",
            "Epoch 411/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8452 - val_loss: 0.6580 - val_accuracy: 0.7398\n",
            "Epoch 412/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8513 - val_loss: 0.6622 - val_accuracy: 0.7398\n",
            "Epoch 413/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8473 - val_loss: 0.7274 - val_accuracy: 0.7317\n",
            "Epoch 414/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8513 - val_loss: 0.6977 - val_accuracy: 0.7073\n",
            "Epoch 415/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8330 - val_loss: 0.6660 - val_accuracy: 0.7154\n",
            "Epoch 416/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8391 - val_loss: 0.6955 - val_accuracy: 0.7480\n",
            "Epoch 417/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8697 - val_loss: 0.7296 - val_accuracy: 0.7154\n",
            "Epoch 418/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8391 - val_loss: 0.7493 - val_accuracy: 0.6992\n",
            "Epoch 419/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8493 - val_loss: 0.7153 - val_accuracy: 0.7317\n",
            "Epoch 420/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8452 - val_loss: 0.7990 - val_accuracy: 0.7154\n",
            "Epoch 421/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8615 - val_loss: 0.7895 - val_accuracy: 0.6911\n",
            "Epoch 422/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8493 - val_loss: 0.7095 - val_accuracy: 0.7317\n",
            "Epoch 423/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8493 - val_loss: 0.7572 - val_accuracy: 0.7154\n",
            "Epoch 424/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8493 - val_loss: 0.6705 - val_accuracy: 0.7398\n",
            "Epoch 425/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8473 - val_loss: 0.6774 - val_accuracy: 0.7561\n",
            "Epoch 426/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8473 - val_loss: 0.6836 - val_accuracy: 0.7886\n",
            "Epoch 427/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8513 - val_loss: 0.7066 - val_accuracy: 0.7236\n",
            "Epoch 428/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8411 - val_loss: 0.7026 - val_accuracy: 0.7398\n",
            "Epoch 429/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8473 - val_loss: 0.7601 - val_accuracy: 0.6829\n",
            "Epoch 430/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8391 - val_loss: 0.7644 - val_accuracy: 0.7236\n",
            "Epoch 431/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8513 - val_loss: 0.7370 - val_accuracy: 0.6829\n",
            "Epoch 432/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8513 - val_loss: 0.7224 - val_accuracy: 0.7236\n",
            "Epoch 433/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8574 - val_loss: 0.7151 - val_accuracy: 0.6911\n",
            "Epoch 434/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8493 - val_loss: 0.7289 - val_accuracy: 0.7317\n",
            "Epoch 435/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8432 - val_loss: 0.7236 - val_accuracy: 0.7154\n",
            "Epoch 436/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8595 - val_loss: 0.7730 - val_accuracy: 0.7480\n",
            "Epoch 437/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8432 - val_loss: 0.8565 - val_accuracy: 0.6992\n",
            "Epoch 438/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8473 - val_loss: 0.8174 - val_accuracy: 0.6911\n",
            "Epoch 439/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8615 - val_loss: 0.7342 - val_accuracy: 0.7317\n",
            "Epoch 440/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8391 - val_loss: 0.8214 - val_accuracy: 0.6911\n",
            "Epoch 441/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8615 - val_loss: 0.7801 - val_accuracy: 0.7236\n",
            "Epoch 442/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8554 - val_loss: 0.7466 - val_accuracy: 0.7561\n",
            "Epoch 443/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8554 - val_loss: 0.7070 - val_accuracy: 0.7480\n",
            "Epoch 444/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8473 - val_loss: 0.8020 - val_accuracy: 0.6829\n",
            "Epoch 445/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8615 - val_loss: 0.7393 - val_accuracy: 0.7398\n",
            "Epoch 446/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8513 - val_loss: 0.7243 - val_accuracy: 0.6829\n",
            "Epoch 447/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8595 - val_loss: 0.7394 - val_accuracy: 0.7236\n",
            "Epoch 448/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8473 - val_loss: 0.7672 - val_accuracy: 0.7398\n",
            "Epoch 449/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8350 - val_loss: 0.7555 - val_accuracy: 0.7073\n",
            "Epoch 450/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8534 - val_loss: 0.7464 - val_accuracy: 0.7398\n",
            "Epoch 451/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8452 - val_loss: 0.7104 - val_accuracy: 0.7398\n",
            "Epoch 452/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8452 - val_loss: 0.6964 - val_accuracy: 0.7317\n",
            "Epoch 453/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8676 - val_loss: 0.7933 - val_accuracy: 0.7317\n",
            "Epoch 454/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8513 - val_loss: 0.7521 - val_accuracy: 0.7236\n",
            "Epoch 455/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8635 - val_loss: 0.7813 - val_accuracy: 0.7154\n",
            "Epoch 456/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8432 - val_loss: 0.6907 - val_accuracy: 0.7073\n",
            "Epoch 457/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8778 - val_loss: 0.7991 - val_accuracy: 0.6829\n",
            "Epoch 458/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8635 - val_loss: 0.7434 - val_accuracy: 0.7561\n",
            "Epoch 459/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8452 - val_loss: 0.7833 - val_accuracy: 0.7236\n",
            "Epoch 460/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8615 - val_loss: 0.7519 - val_accuracy: 0.7154\n",
            "Epoch 461/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8513 - val_loss: 0.7962 - val_accuracy: 0.7236\n",
            "Epoch 462/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8615 - val_loss: 0.7640 - val_accuracy: 0.7154\n",
            "Epoch 463/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8635 - val_loss: 0.7684 - val_accuracy: 0.6667\n",
            "Epoch 464/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8778 - val_loss: 0.7727 - val_accuracy: 0.7154\n",
            "Epoch 465/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8513 - val_loss: 0.7745 - val_accuracy: 0.6585\n",
            "Epoch 466/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8534 - val_loss: 0.7690 - val_accuracy: 0.7073\n",
            "Epoch 467/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8635 - val_loss: 0.7562 - val_accuracy: 0.7561\n",
            "Epoch 468/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8554 - val_loss: 0.7948 - val_accuracy: 0.7236\n",
            "Epoch 469/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8534 - val_loss: 0.7490 - val_accuracy: 0.7642\n",
            "Epoch 470/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8615 - val_loss: 0.7645 - val_accuracy: 0.6911\n",
            "Epoch 471/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8697 - val_loss: 0.8441 - val_accuracy: 0.6911\n",
            "Epoch 472/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8778 - val_loss: 0.7901 - val_accuracy: 0.7398\n",
            "Epoch 473/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8676 - val_loss: 0.7739 - val_accuracy: 0.6992\n",
            "Epoch 474/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.8656 - val_loss: 0.8994 - val_accuracy: 0.7073\n",
            "Epoch 475/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8717 - val_loss: 0.8045 - val_accuracy: 0.7154\n",
            "Epoch 476/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8737 - val_loss: 0.7489 - val_accuracy: 0.7398\n",
            "Epoch 477/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2740 - accuracy: 0.8819 - val_loss: 0.7860 - val_accuracy: 0.7398\n",
            "Epoch 478/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8737 - val_loss: 0.7954 - val_accuracy: 0.7398\n",
            "Epoch 479/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8513 - val_loss: 0.7676 - val_accuracy: 0.7317\n",
            "Epoch 480/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8513 - val_loss: 0.7788 - val_accuracy: 0.6829\n",
            "Epoch 481/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8554 - val_loss: 0.9122 - val_accuracy: 0.6585\n",
            "Epoch 482/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8513 - val_loss: 0.8533 - val_accuracy: 0.7236\n",
            "Epoch 483/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8676 - val_loss: 0.8276 - val_accuracy: 0.7073\n",
            "Epoch 484/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8758 - val_loss: 0.7891 - val_accuracy: 0.7561\n",
            "Epoch 485/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8574 - val_loss: 0.7339 - val_accuracy: 0.7398\n",
            "Epoch 486/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8574 - val_loss: 0.7871 - val_accuracy: 0.7154\n",
            "Epoch 487/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8615 - val_loss: 0.8240 - val_accuracy: 0.7154\n",
            "Epoch 488/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8635 - val_loss: 0.7632 - val_accuracy: 0.7154\n",
            "Epoch 489/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8656 - val_loss: 0.8247 - val_accuracy: 0.7073\n",
            "Epoch 490/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8737 - val_loss: 0.8075 - val_accuracy: 0.7154\n",
            "Epoch 491/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8676 - val_loss: 0.7989 - val_accuracy: 0.7154\n",
            "Epoch 492/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8635 - val_loss: 0.7925 - val_accuracy: 0.7073\n",
            "Epoch 493/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8798 - val_loss: 0.8671 - val_accuracy: 0.7154\n",
            "Epoch 494/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8737 - val_loss: 0.7600 - val_accuracy: 0.7317\n",
            "Epoch 495/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8513 - val_loss: 0.8158 - val_accuracy: 0.7236\n",
            "Epoch 496/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8595 - val_loss: 0.8593 - val_accuracy: 0.6911\n",
            "Epoch 497/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8717 - val_loss: 0.7772 - val_accuracy: 0.7317\n",
            "Epoch 498/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8758 - val_loss: 0.8175 - val_accuracy: 0.7073\n",
            "Epoch 499/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8798 - val_loss: 0.7852 - val_accuracy: 0.7398\n",
            "Epoch 500/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8615 - val_loss: 0.8040 - val_accuracy: 0.6992\n",
            "Epoch 501/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8737 - val_loss: 0.8069 - val_accuracy: 0.7154\n",
            "Epoch 502/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8859 - val_loss: 0.8306 - val_accuracy: 0.6911\n",
            "Epoch 503/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8737 - val_loss: 0.8469 - val_accuracy: 0.7073\n",
            "Epoch 504/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.8819 - val_loss: 0.7958 - val_accuracy: 0.7398\n",
            "Epoch 505/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8656 - val_loss: 0.9759 - val_accuracy: 0.6911\n",
            "Epoch 506/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8819 - val_loss: 0.8444 - val_accuracy: 0.7398\n",
            "Epoch 507/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8778 - val_loss: 0.8799 - val_accuracy: 0.7236\n",
            "Epoch 508/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8859 - val_loss: 0.8985 - val_accuracy: 0.7154\n",
            "Epoch 509/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8921 - val_loss: 0.8466 - val_accuracy: 0.7073\n",
            "Epoch 510/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8839 - val_loss: 0.8973 - val_accuracy: 0.6911\n",
            "Epoch 511/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8798 - val_loss: 0.9104 - val_accuracy: 0.6911\n",
            "Epoch 512/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8778 - val_loss: 0.8220 - val_accuracy: 0.7398\n",
            "Epoch 513/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8717 - val_loss: 0.8658 - val_accuracy: 0.6992\n",
            "Epoch 514/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8697 - val_loss: 0.8669 - val_accuracy: 0.6748\n",
            "Epoch 515/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8656 - val_loss: 0.9008 - val_accuracy: 0.7073\n",
            "Epoch 516/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8778 - val_loss: 0.9319 - val_accuracy: 0.6992\n",
            "Epoch 517/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8819 - val_loss: 0.9097 - val_accuracy: 0.7154\n",
            "Epoch 518/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8676 - val_loss: 0.8261 - val_accuracy: 0.7398\n",
            "Epoch 519/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8941 - val_loss: 0.8368 - val_accuracy: 0.7073\n",
            "Epoch 520/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8839 - val_loss: 0.8656 - val_accuracy: 0.6504\n",
            "Epoch 521/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8758 - val_loss: 0.9449 - val_accuracy: 0.6829\n",
            "Epoch 522/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8819 - val_loss: 0.9517 - val_accuracy: 0.7073\n",
            "Epoch 523/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8676 - val_loss: 0.8311 - val_accuracy: 0.7073\n",
            "Epoch 524/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.8859 - val_loss: 0.9576 - val_accuracy: 0.6829\n",
            "Epoch 525/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8656 - val_loss: 0.8166 - val_accuracy: 0.7398\n",
            "Epoch 526/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8859 - val_loss: 0.9578 - val_accuracy: 0.6667\n",
            "Epoch 527/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.9022 - val_loss: 0.9287 - val_accuracy: 0.7073\n",
            "Epoch 528/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8798 - val_loss: 0.8972 - val_accuracy: 0.6911\n",
            "Epoch 529/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8941 - val_loss: 0.8829 - val_accuracy: 0.7154\n",
            "Epoch 530/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8798 - val_loss: 0.8719 - val_accuracy: 0.7073\n",
            "Epoch 531/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8819 - val_loss: 0.8613 - val_accuracy: 0.7073\n",
            "Epoch 532/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8900 - val_loss: 0.9155 - val_accuracy: 0.7073\n",
            "Epoch 533/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8737 - val_loss: 1.0236 - val_accuracy: 0.7154\n",
            "Epoch 534/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8839 - val_loss: 0.8513 - val_accuracy: 0.6667\n",
            "Epoch 535/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8778 - val_loss: 0.9353 - val_accuracy: 0.6423\n",
            "Epoch 536/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.8819 - val_loss: 1.0266 - val_accuracy: 0.7317\n",
            "Epoch 537/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8737 - val_loss: 1.0223 - val_accuracy: 0.6585\n",
            "Epoch 538/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8982 - val_loss: 1.0125 - val_accuracy: 0.6911\n",
            "Epoch 539/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8819 - val_loss: 1.0152 - val_accuracy: 0.6341\n",
            "Epoch 540/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8717 - val_loss: 0.9124 - val_accuracy: 0.6748\n",
            "Epoch 541/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8798 - val_loss: 0.8973 - val_accuracy: 0.6992\n",
            "Epoch 542/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8900 - val_loss: 0.8774 - val_accuracy: 0.7154\n",
            "Epoch 543/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8737 - val_loss: 0.8749 - val_accuracy: 0.7236\n",
            "Epoch 544/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8982 - val_loss: 0.9546 - val_accuracy: 0.6992\n",
            "Epoch 545/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8758 - val_loss: 0.9371 - val_accuracy: 0.7073\n",
            "Epoch 546/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8778 - val_loss: 0.9162 - val_accuracy: 0.6992\n",
            "Epoch 547/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8839 - val_loss: 0.9660 - val_accuracy: 0.6585\n",
            "Epoch 548/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8941 - val_loss: 0.9954 - val_accuracy: 0.6911\n",
            "Epoch 549/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8595 - val_loss: 0.9628 - val_accuracy: 0.6423\n",
            "Epoch 550/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8758 - val_loss: 0.9651 - val_accuracy: 0.6504\n",
            "Epoch 551/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8819 - val_loss: 0.8356 - val_accuracy: 0.6911\n",
            "Epoch 552/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8941 - val_loss: 0.9443 - val_accuracy: 0.7073\n",
            "Epoch 553/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8941 - val_loss: 0.9996 - val_accuracy: 0.6992\n",
            "Epoch 554/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8859 - val_loss: 0.9143 - val_accuracy: 0.6667\n",
            "Epoch 555/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9002 - val_loss: 1.0105 - val_accuracy: 0.6585\n",
            "Epoch 556/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8717 - val_loss: 0.9773 - val_accuracy: 0.6992\n",
            "Epoch 557/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8798 - val_loss: 0.9340 - val_accuracy: 0.7154\n",
            "Epoch 558/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8839 - val_loss: 0.9221 - val_accuracy: 0.6992\n",
            "Epoch 559/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8859 - val_loss: 0.9822 - val_accuracy: 0.7317\n",
            "Epoch 560/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8982 - val_loss: 0.9502 - val_accuracy: 0.6667\n",
            "Epoch 561/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8880 - val_loss: 0.9817 - val_accuracy: 0.7154\n",
            "Epoch 562/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8900 - val_loss: 0.9557 - val_accuracy: 0.6748\n",
            "Epoch 563/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8819 - val_loss: 0.9342 - val_accuracy: 0.6829\n",
            "Epoch 564/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.8880 - val_loss: 1.0406 - val_accuracy: 0.6098\n",
            "Epoch 565/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8880 - val_loss: 0.9292 - val_accuracy: 0.6911\n",
            "Epoch 566/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8880 - val_loss: 0.9866 - val_accuracy: 0.6992\n",
            "Epoch 567/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9002 - val_loss: 0.9949 - val_accuracy: 0.7073\n",
            "Epoch 568/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8656 - val_loss: 0.9744 - val_accuracy: 0.6911\n",
            "Epoch 569/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8798 - val_loss: 0.9781 - val_accuracy: 0.6748\n",
            "Epoch 570/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.8839 - val_loss: 1.0609 - val_accuracy: 0.6667\n",
            "Epoch 571/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.8961 - val_loss: 0.9769 - val_accuracy: 0.6992\n",
            "Epoch 572/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.8880 - val_loss: 1.0095 - val_accuracy: 0.6911\n",
            "Epoch 573/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.8839 - val_loss: 1.0062 - val_accuracy: 0.6911\n",
            "Epoch 574/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9022 - val_loss: 0.9973 - val_accuracy: 0.6829\n",
            "Epoch 575/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.8921 - val_loss: 0.9148 - val_accuracy: 0.6829\n",
            "Epoch 576/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9063 - val_loss: 1.0230 - val_accuracy: 0.6179\n",
            "Epoch 577/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.8982 - val_loss: 0.9552 - val_accuracy: 0.6667\n",
            "Epoch 578/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9022 - val_loss: 1.0671 - val_accuracy: 0.6504\n",
            "Epoch 579/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.8839 - val_loss: 0.9824 - val_accuracy: 0.6992\n",
            "Epoch 580/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9022 - val_loss: 0.9446 - val_accuracy: 0.7317\n",
            "Epoch 581/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8900 - val_loss: 0.9500 - val_accuracy: 0.6748\n",
            "Epoch 582/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8921 - val_loss: 0.9542 - val_accuracy: 0.7073\n",
            "Epoch 583/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8921 - val_loss: 0.9604 - val_accuracy: 0.7236\n",
            "Epoch 584/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.8859 - val_loss: 0.9986 - val_accuracy: 0.6829\n",
            "Epoch 585/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.8921 - val_loss: 1.0507 - val_accuracy: 0.6667\n",
            "Epoch 586/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.8941 - val_loss: 1.0229 - val_accuracy: 0.6504\n",
            "Epoch 587/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8941 - val_loss: 1.0449 - val_accuracy: 0.6748\n",
            "Epoch 588/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8880 - val_loss: 1.0464 - val_accuracy: 0.7073\n",
            "Epoch 589/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.8900 - val_loss: 1.0740 - val_accuracy: 0.6667\n",
            "Epoch 590/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.8900 - val_loss: 0.9948 - val_accuracy: 0.6992\n",
            "Epoch 591/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9104 - val_loss: 0.9736 - val_accuracy: 0.7073\n",
            "Epoch 592/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8880 - val_loss: 1.0869 - val_accuracy: 0.6748\n",
            "Epoch 593/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9022 - val_loss: 1.0491 - val_accuracy: 0.6667\n",
            "Epoch 594/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9043 - val_loss: 1.0755 - val_accuracy: 0.7236\n",
            "Epoch 595/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.8839 - val_loss: 0.9491 - val_accuracy: 0.6992\n",
            "Epoch 596/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9104 - val_loss: 1.0105 - val_accuracy: 0.6504\n",
            "Epoch 597/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9084 - val_loss: 0.9708 - val_accuracy: 0.6748\n",
            "Epoch 598/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.8900 - val_loss: 1.0309 - val_accuracy: 0.6829\n",
            "Epoch 599/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8941 - val_loss: 1.0231 - val_accuracy: 0.6911\n",
            "Epoch 600/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9002 - val_loss: 1.1006 - val_accuracy: 0.6911\n",
            "Epoch 601/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.8900 - val_loss: 1.1385 - val_accuracy: 0.6667\n",
            "Epoch 602/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.8961 - val_loss: 1.0459 - val_accuracy: 0.6748\n",
            "Epoch 603/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9104 - val_loss: 1.0729 - val_accuracy: 0.6504\n",
            "Epoch 604/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.8982 - val_loss: 1.1036 - val_accuracy: 0.6829\n",
            "Epoch 605/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8900 - val_loss: 1.1308 - val_accuracy: 0.6992\n",
            "Epoch 606/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9002 - val_loss: 1.0800 - val_accuracy: 0.6829\n",
            "Epoch 607/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.8941 - val_loss: 1.0722 - val_accuracy: 0.6992\n",
            "Epoch 608/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9022 - val_loss: 1.1043 - val_accuracy: 0.6748\n",
            "Epoch 609/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9206 - val_loss: 1.0993 - val_accuracy: 0.6829\n",
            "Epoch 610/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.8982 - val_loss: 1.1477 - val_accuracy: 0.6667\n",
            "Epoch 611/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9022 - val_loss: 1.0104 - val_accuracy: 0.6748\n",
            "Epoch 612/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9124 - val_loss: 1.0346 - val_accuracy: 0.6829\n",
            "Epoch 613/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9124 - val_loss: 1.1345 - val_accuracy: 0.6667\n",
            "Epoch 614/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.9002 - val_loss: 1.1969 - val_accuracy: 0.6992\n",
            "Epoch 615/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9165 - val_loss: 1.2633 - val_accuracy: 0.6667\n",
            "Epoch 616/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9043 - val_loss: 1.1200 - val_accuracy: 0.7236\n",
            "Epoch 617/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.8941 - val_loss: 1.1250 - val_accuracy: 0.6667\n",
            "Epoch 618/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.8941 - val_loss: 1.0478 - val_accuracy: 0.6748\n",
            "Epoch 619/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.8961 - val_loss: 1.0584 - val_accuracy: 0.6911\n",
            "Epoch 620/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9104 - val_loss: 1.0694 - val_accuracy: 0.6585\n",
            "Epoch 621/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9185 - val_loss: 1.0001 - val_accuracy: 0.7317\n",
            "Epoch 622/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9063 - val_loss: 1.0931 - val_accuracy: 0.7073\n",
            "Epoch 623/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.8961 - val_loss: 1.0289 - val_accuracy: 0.7073\n",
            "Epoch 624/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9124 - val_loss: 1.2159 - val_accuracy: 0.6504\n",
            "Epoch 625/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9084 - val_loss: 1.1904 - val_accuracy: 0.6748\n",
            "Epoch 626/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9145 - val_loss: 1.0714 - val_accuracy: 0.6667\n",
            "Epoch 627/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9145 - val_loss: 1.0570 - val_accuracy: 0.6748\n",
            "Epoch 628/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.8941 - val_loss: 1.1490 - val_accuracy: 0.6585\n",
            "Epoch 629/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9206 - val_loss: 1.1926 - val_accuracy: 0.6829\n",
            "Epoch 630/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9022 - val_loss: 1.1320 - val_accuracy: 0.6829\n",
            "Epoch 631/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9206 - val_loss: 1.1521 - val_accuracy: 0.7073\n",
            "Epoch 632/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9185 - val_loss: 1.2787 - val_accuracy: 0.6911\n",
            "Epoch 633/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.8961 - val_loss: 1.3407 - val_accuracy: 0.6748\n",
            "Epoch 634/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9084 - val_loss: 1.1341 - val_accuracy: 0.6911\n",
            "Epoch 635/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9043 - val_loss: 1.2916 - val_accuracy: 0.6829\n",
            "Epoch 636/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9124 - val_loss: 1.1198 - val_accuracy: 0.6260\n",
            "Epoch 637/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.8982 - val_loss: 1.1427 - val_accuracy: 0.6504\n",
            "Epoch 638/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9185 - val_loss: 1.1390 - val_accuracy: 0.7073\n",
            "Epoch 639/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9226 - val_loss: 1.1567 - val_accuracy: 0.6748\n",
            "Epoch 640/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9002 - val_loss: 1.1109 - val_accuracy: 0.6911\n",
            "Epoch 641/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9206 - val_loss: 1.1129 - val_accuracy: 0.6829\n",
            "Epoch 642/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9104 - val_loss: 1.1664 - val_accuracy: 0.6179\n",
            "Epoch 643/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9022 - val_loss: 1.1887 - val_accuracy: 0.6260\n",
            "Epoch 644/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9022 - val_loss: 1.1440 - val_accuracy: 0.6748\n",
            "Epoch 645/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9145 - val_loss: 1.1861 - val_accuracy: 0.6585\n",
            "Epoch 646/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9246 - val_loss: 1.2842 - val_accuracy: 0.6992\n",
            "Epoch 647/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.8982 - val_loss: 1.2270 - val_accuracy: 0.7154\n",
            "Epoch 648/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9084 - val_loss: 1.1065 - val_accuracy: 0.7073\n",
            "Epoch 649/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9063 - val_loss: 1.1826 - val_accuracy: 0.6992\n",
            "Epoch 650/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9002 - val_loss: 1.3161 - val_accuracy: 0.6829\n",
            "Epoch 651/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.8961 - val_loss: 1.2832 - val_accuracy: 0.6748\n",
            "Epoch 652/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9124 - val_loss: 1.1661 - val_accuracy: 0.7154\n",
            "Epoch 653/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9246 - val_loss: 1.1093 - val_accuracy: 0.6911\n",
            "Epoch 654/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9104 - val_loss: 1.2088 - val_accuracy: 0.6829\n",
            "Epoch 655/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9328 - val_loss: 1.1777 - val_accuracy: 0.7073\n",
            "Epoch 656/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9043 - val_loss: 1.2398 - val_accuracy: 0.6829\n",
            "Epoch 657/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9185 - val_loss: 1.4027 - val_accuracy: 0.6911\n",
            "Epoch 658/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9226 - val_loss: 1.2135 - val_accuracy: 0.6667\n",
            "Epoch 659/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9124 - val_loss: 1.2543 - val_accuracy: 0.6667\n",
            "Epoch 660/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9022 - val_loss: 1.2959 - val_accuracy: 0.6341\n",
            "Epoch 661/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9104 - val_loss: 1.2235 - val_accuracy: 0.6829\n",
            "Epoch 662/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9063 - val_loss: 1.3142 - val_accuracy: 0.7073\n",
            "Epoch 663/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9165 - val_loss: 1.2841 - val_accuracy: 0.6992\n",
            "Epoch 664/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9206 - val_loss: 1.2463 - val_accuracy: 0.6748\n",
            "Epoch 665/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9124 - val_loss: 1.3336 - val_accuracy: 0.6585\n",
            "Epoch 666/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9043 - val_loss: 1.2686 - val_accuracy: 0.6667\n",
            "Epoch 667/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9287 - val_loss: 1.1990 - val_accuracy: 0.6748\n",
            "Epoch 668/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9124 - val_loss: 1.2816 - val_accuracy: 0.6179\n",
            "Epoch 669/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9328 - val_loss: 1.2982 - val_accuracy: 0.6748\n",
            "Epoch 670/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9145 - val_loss: 1.2976 - val_accuracy: 0.6667\n",
            "Epoch 671/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9145 - val_loss: 1.3024 - val_accuracy: 0.7236\n",
            "Epoch 672/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9206 - val_loss: 1.2607 - val_accuracy: 0.6911\n",
            "Epoch 673/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9185 - val_loss: 1.2929 - val_accuracy: 0.6992\n",
            "Epoch 674/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9226 - val_loss: 1.2470 - val_accuracy: 0.7236\n",
            "Epoch 675/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9043 - val_loss: 1.4069 - val_accuracy: 0.6992\n",
            "Epoch 676/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9206 - val_loss: 1.3643 - val_accuracy: 0.6016\n",
            "Epoch 677/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8982 - val_loss: 1.2962 - val_accuracy: 0.6829\n",
            "Epoch 678/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9165 - val_loss: 1.2942 - val_accuracy: 0.6829\n",
            "Epoch 679/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9185 - val_loss: 1.1886 - val_accuracy: 0.6992\n",
            "Epoch 680/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9287 - val_loss: 1.2324 - val_accuracy: 0.7154\n",
            "Epoch 681/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9145 - val_loss: 1.2744 - val_accuracy: 0.6829\n",
            "Epoch 682/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9022 - val_loss: 1.2121 - val_accuracy: 0.6585\n",
            "Epoch 683/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9145 - val_loss: 1.1747 - val_accuracy: 0.7154\n",
            "Epoch 684/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9084 - val_loss: 1.3369 - val_accuracy: 0.7236\n",
            "Epoch 685/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9328 - val_loss: 1.3240 - val_accuracy: 0.7317\n",
            "Epoch 686/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9267 - val_loss: 1.2987 - val_accuracy: 0.7073\n",
            "Epoch 687/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9165 - val_loss: 1.3324 - val_accuracy: 0.6179\n",
            "Epoch 688/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9185 - val_loss: 1.1601 - val_accuracy: 0.6992\n",
            "Epoch 689/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9124 - val_loss: 1.2183 - val_accuracy: 0.6911\n",
            "Epoch 690/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9328 - val_loss: 1.3570 - val_accuracy: 0.7480\n",
            "Epoch 691/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9246 - val_loss: 1.3356 - val_accuracy: 0.6748\n",
            "Epoch 692/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9104 - val_loss: 1.4962 - val_accuracy: 0.6748\n",
            "Epoch 693/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.8961 - val_loss: 1.3411 - val_accuracy: 0.6667\n",
            "Epoch 694/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9185 - val_loss: 1.5186 - val_accuracy: 0.6829\n",
            "Epoch 695/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9084 - val_loss: 1.3570 - val_accuracy: 0.6016\n",
            "Epoch 696/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9063 - val_loss: 1.3408 - val_accuracy: 0.7073\n",
            "Epoch 697/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9287 - val_loss: 1.4146 - val_accuracy: 0.6829\n",
            "Epoch 698/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9267 - val_loss: 1.4622 - val_accuracy: 0.6911\n",
            "Epoch 699/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9145 - val_loss: 1.3401 - val_accuracy: 0.6667\n",
            "Epoch 700/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9185 - val_loss: 1.4244 - val_accuracy: 0.6260\n",
            "Epoch 701/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9226 - val_loss: 1.2825 - val_accuracy: 0.6911\n",
            "Epoch 702/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9124 - val_loss: 1.4788 - val_accuracy: 0.6585\n",
            "Epoch 703/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9246 - val_loss: 1.1903 - val_accuracy: 0.6667\n",
            "Epoch 704/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9226 - val_loss: 1.5354 - val_accuracy: 0.6829\n",
            "Epoch 705/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9246 - val_loss: 1.2354 - val_accuracy: 0.6748\n",
            "Epoch 706/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9267 - val_loss: 1.3440 - val_accuracy: 0.6992\n",
            "Epoch 707/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9246 - val_loss: 1.4620 - val_accuracy: 0.6748\n",
            "Epoch 708/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9084 - val_loss: 1.3126 - val_accuracy: 0.7073\n",
            "Epoch 709/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9328 - val_loss: 1.3361 - val_accuracy: 0.6992\n",
            "Epoch 710/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9084 - val_loss: 1.3394 - val_accuracy: 0.7317\n",
            "Epoch 711/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9287 - val_loss: 1.3288 - val_accuracy: 0.6748\n",
            "Epoch 712/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9124 - val_loss: 1.2995 - val_accuracy: 0.6504\n",
            "Epoch 713/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9063 - val_loss: 1.3530 - val_accuracy: 0.6748\n",
            "Epoch 714/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9226 - val_loss: 1.3916 - val_accuracy: 0.6748\n",
            "Epoch 715/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9165 - val_loss: 1.3627 - val_accuracy: 0.6748\n",
            "Epoch 716/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9124 - val_loss: 1.4068 - val_accuracy: 0.7236\n",
            "Epoch 717/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9185 - val_loss: 1.3470 - val_accuracy: 0.7154\n",
            "Epoch 718/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9267 - val_loss: 1.3459 - val_accuracy: 0.6585\n",
            "Epoch 719/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9389 - val_loss: 1.2750 - val_accuracy: 0.7236\n",
            "Epoch 720/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9287 - val_loss: 1.4223 - val_accuracy: 0.6992\n",
            "Epoch 721/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9145 - val_loss: 1.4659 - val_accuracy: 0.6667\n",
            "Epoch 722/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9206 - val_loss: 1.4921 - val_accuracy: 0.7073\n",
            "Epoch 723/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9246 - val_loss: 1.4468 - val_accuracy: 0.7154\n",
            "Epoch 724/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9328 - val_loss: 1.4605 - val_accuracy: 0.6098\n",
            "Epoch 725/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9165 - val_loss: 1.4483 - val_accuracy: 0.6911\n",
            "Epoch 726/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9308 - val_loss: 1.3198 - val_accuracy: 0.6829\n",
            "Epoch 727/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9226 - val_loss: 1.3398 - val_accuracy: 0.6992\n",
            "Epoch 728/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9267 - val_loss: 1.4121 - val_accuracy: 0.7073\n",
            "Epoch 729/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9267 - val_loss: 1.6158 - val_accuracy: 0.6423\n",
            "Epoch 730/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9084 - val_loss: 1.4234 - val_accuracy: 0.7154\n",
            "Epoch 731/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9308 - val_loss: 1.3007 - val_accuracy: 0.6585\n",
            "Epoch 732/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9145 - val_loss: 1.4329 - val_accuracy: 0.6829\n",
            "Epoch 733/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9206 - val_loss: 1.3592 - val_accuracy: 0.6423\n",
            "Epoch 734/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9348 - val_loss: 1.3903 - val_accuracy: 0.6829\n",
            "Epoch 735/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9267 - val_loss: 1.3761 - val_accuracy: 0.6341\n",
            "Epoch 736/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9409 - val_loss: 1.3072 - val_accuracy: 0.7154\n",
            "Epoch 737/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9267 - val_loss: 1.3390 - val_accuracy: 0.6504\n",
            "Epoch 738/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9185 - val_loss: 1.4084 - val_accuracy: 0.6992\n",
            "Epoch 739/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9348 - val_loss: 1.3639 - val_accuracy: 0.7073\n",
            "Epoch 740/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9409 - val_loss: 1.6172 - val_accuracy: 0.6748\n",
            "Epoch 741/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9246 - val_loss: 1.4405 - val_accuracy: 0.6992\n",
            "Epoch 742/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9206 - val_loss: 1.5014 - val_accuracy: 0.6667\n",
            "Epoch 743/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9267 - val_loss: 1.5184 - val_accuracy: 0.6260\n",
            "Epoch 744/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9165 - val_loss: 1.4298 - val_accuracy: 0.6341\n",
            "Epoch 745/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9165 - val_loss: 1.3615 - val_accuracy: 0.6829\n",
            "Epoch 746/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9369 - val_loss: 1.5403 - val_accuracy: 0.6667\n",
            "Epoch 747/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9389 - val_loss: 1.4730 - val_accuracy: 0.6992\n",
            "Epoch 748/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9308 - val_loss: 1.6903 - val_accuracy: 0.6504\n",
            "Epoch 749/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9246 - val_loss: 1.5323 - val_accuracy: 0.6423\n",
            "Epoch 750/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9308 - val_loss: 1.4378 - val_accuracy: 0.6260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "3d75b817-ea04-4565-8c65-ef0598a728f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "ae269981-89e3-459c-bfc9-27ba08a23179"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3914 - accuracy: 0.6558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "c18a456a-f469-4859-9b51-720cfb3f8afa"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.89434725, 0.10565273]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "13544cb3-089f-4e22-c60c-1a406effccdd"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}
