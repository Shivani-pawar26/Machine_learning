{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_6-neural_network_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivani-pawar26/Machine_learning/blob/main/Lab_6_neural_network_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 â€“ Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZg_G5MQ4L5",
        "outputId": "f05bd5f4-d96f-46f0-a802-9db93a1bb520"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "1cd58ab2-30ff-43e9-f91e-10b90b779083"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb99417f-221c-418e-d115-7e8ec8cfdff0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 01_inputFinction.py\n",
            "'Alexa skillsets'\n",
            "'Anandam Application Form (For Girls) Year 2021.pdf'\n",
            "'Bajaj Finserv Health - Data Science - Qualifier 1 Challenge - MP Campus Pool.gdoc'\n",
            "'Bajaj Finserv Health - Data Science - Qualifier 1 Challenge - MP Campus Pool.pdf'\n",
            " best_fit.cpp\n",
            " Classroom\n",
            "'CO BATCH ERP LOGIN ID PASSWORD  (8).gsheet'\n",
            "'codechef program pdf.pdf'\n",
            "'CO-Github Repository-Link sheet.gsheet'\n",
            "'Colab Notebooks'\n",
            "'CO V SEM TOC LAB JULY-DEC 2021.xlsx'\n",
            " diabetes.csv\n",
            "'edx certificate....pdf'\n",
            "'Getting started.pdf'\n",
            " IMG_20210408_200021.jpg\n",
            "'IMG_20210511_122102 (1).jpg'\n",
            " IMG_20210511_122102.jpg\n",
            "'IMG_20210529_141532 (1).jpg'\n",
            " IMG_20210529_141532.jpg\n",
            " IMG_20210529_143913.jpg\n",
            " IMG-20210724-WA0013.jpg\n",
            "'IMG_20210820_224852 (1).jpg'\n",
            " IMG_20210820_224852.jpg\n",
            " IMG_20210820_231134.jpg\n",
            " IMG-20210831-WA0002.jpg\n",
            " Income.pdf\n",
            "'IWT-Assignment '\n",
            "'library Card.pdf'\n",
            "'Linux Assignment'\n",
            " Parent_AFD_2294988_2912202003251694.pdf\n",
            "'response sheet of C0-304(MST-I).gsheet'\n",
            "'Screenshot_2021-08-06-12-31-10-051_com (1).google.android.gm.jpg'\n",
            " Screenshot_2021-08-06-12-31-10-051_com.google.android.gm.jpg\n",
            " Share\n",
            "'Shivani Pawar (CO-53)ADA.pdf'\n",
            "'Shivani Pawar (CO-53)_Assignment_CSO.pdf.pdf'\n",
            "'Shivani Pawar (CO-53)CSO.pdf.pdf'\n",
            "'Shivani Pawar CO-53 (IWT Test).pdf'\n",
            "'Shivani pawar.pdf'\n",
            "'shivani pawar.png'\n",
            "'sql(basic).png'\n",
            " Student_AFD_2294988_2912202003251558.pdf\n",
            "'Transfer Learning'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "fc8a98b1-f1f3-4dba-de05-e924e6fdcad7"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13ccf229-7c87-4f46-9886-eb21ef984778\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13ccf229-7c87-4f46-9886-eb21ef984778')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13ccf229-7c87-4f46-9886-eb21ef984778 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13ccf229-7c87-4f46-9886-eb21ef984778');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "2aaa3126-9617-42d1-a4bb-9a03979e0c53"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "3f7417dc-76df-4d21-f6c9-71501345e8a2"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "caf2a817-27fc-4ac6-a1d9-690bb6fd1212"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "8f3c8435-27e2-4784-8668-cec81e2b5779"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "c6fbeeb9-31cb-46bc-86c4-3c756a7b23aa"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "e079a5ed-522a-4421-8c0f-8acad3b66e51"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNfmvbMOXeku",
        "outputId": "49697366-5628-4338-8524-a7c3aedb5c48"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                108       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 206\n",
            "Trainable params: 206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "aa947a60-6cc6-4e8a-e1c6-f927373a503f"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=1000, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.6913 - accuracy: 0.5804 - val_loss: 0.7020 - val_accuracy: 0.5203\n",
            "Epoch 2/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.6008 - val_loss: 0.7009 - val_accuracy: 0.5366\n",
            "Epoch 3/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6334 - val_loss: 0.6998 - val_accuracy: 0.5447\n",
            "Epoch 4/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.6375 - val_loss: 0.6987 - val_accuracy: 0.5528\n",
            "Epoch 5/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6334 - val_loss: 0.6977 - val_accuracy: 0.5610\n",
            "Epoch 6/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.6456 - val_loss: 0.6968 - val_accuracy: 0.5691\n",
            "Epoch 7/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6477 - val_loss: 0.6959 - val_accuracy: 0.5691\n",
            "Epoch 8/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6558 - val_loss: 0.6950 - val_accuracy: 0.5772\n",
            "Epoch 9/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.6538 - val_loss: 0.6942 - val_accuracy: 0.5772\n",
            "Epoch 10/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6538 - val_loss: 0.6934 - val_accuracy: 0.5772\n",
            "Epoch 11/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.6558 - val_loss: 0.6927 - val_accuracy: 0.5935\n",
            "Epoch 12/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6640 - val_loss: 0.6919 - val_accuracy: 0.5935\n",
            "Epoch 13/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.6680 - val_loss: 0.6913 - val_accuracy: 0.5935\n",
            "Epoch 14/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.6680 - val_loss: 0.6907 - val_accuracy: 0.6016\n",
            "Epoch 15/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.6660 - val_loss: 0.6901 - val_accuracy: 0.6016\n",
            "Epoch 16/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6680 - val_loss: 0.6895 - val_accuracy: 0.6016\n",
            "Epoch 17/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.6680 - val_loss: 0.6890 - val_accuracy: 0.6016\n",
            "Epoch 18/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.6701 - val_loss: 0.6884 - val_accuracy: 0.6098\n",
            "Epoch 19/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.6680 - val_loss: 0.6880 - val_accuracy: 0.6098\n",
            "Epoch 20/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.6701 - val_loss: 0.6875 - val_accuracy: 0.6098\n",
            "Epoch 21/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6701 - val_loss: 0.6871 - val_accuracy: 0.6098\n",
            "Epoch 22/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6701 - val_loss: 0.6867 - val_accuracy: 0.6098\n",
            "Epoch 23/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6701 - val_loss: 0.6863 - val_accuracy: 0.6098\n",
            "Epoch 24/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6701 - val_loss: 0.6859 - val_accuracy: 0.6098\n",
            "Epoch 25/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6701 - val_loss: 0.6856 - val_accuracy: 0.6098\n",
            "Epoch 26/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6701 - val_loss: 0.6852 - val_accuracy: 0.6098\n",
            "Epoch 27/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6701 - val_loss: 0.6849 - val_accuracy: 0.6098\n",
            "Epoch 28/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6701 - val_loss: 0.6846 - val_accuracy: 0.6098\n",
            "Epoch 29/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6701 - val_loss: 0.6844 - val_accuracy: 0.6098\n",
            "Epoch 30/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6701 - val_loss: 0.6841 - val_accuracy: 0.6098\n",
            "Epoch 31/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6680 - val_loss: 0.6838 - val_accuracy: 0.6098\n",
            "Epoch 32/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6680 - val_loss: 0.6836 - val_accuracy: 0.6098\n",
            "Epoch 33/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6680 - val_loss: 0.6834 - val_accuracy: 0.6098\n",
            "Epoch 34/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6680 - val_loss: 0.6831 - val_accuracy: 0.6098\n",
            "Epoch 35/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6680 - val_loss: 0.6829 - val_accuracy: 0.6098\n",
            "Epoch 36/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6680 - val_loss: 0.6827 - val_accuracy: 0.6098\n",
            "Epoch 37/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6680 - val_loss: 0.6826 - val_accuracy: 0.6260\n",
            "Epoch 38/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6680 - val_loss: 0.6824 - val_accuracy: 0.6260\n",
            "Epoch 39/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6680 - val_loss: 0.6822 - val_accuracy: 0.6260\n",
            "Epoch 40/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6680 - val_loss: 0.6820 - val_accuracy: 0.6260\n",
            "Epoch 41/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6680 - val_loss: 0.6819 - val_accuracy: 0.6260\n",
            "Epoch 42/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6680 - val_loss: 0.6817 - val_accuracy: 0.6260\n",
            "Epoch 43/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6680 - val_loss: 0.6816 - val_accuracy: 0.6260\n",
            "Epoch 44/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6680 - val_loss: 0.6815 - val_accuracy: 0.6260\n",
            "Epoch 45/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6680 - val_loss: 0.6813 - val_accuracy: 0.6260\n",
            "Epoch 46/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6680 - val_loss: 0.6812 - val_accuracy: 0.6260\n",
            "Epoch 47/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6680 - val_loss: 0.6811 - val_accuracy: 0.6260\n",
            "Epoch 48/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6680 - val_loss: 0.6810 - val_accuracy: 0.6260\n",
            "Epoch 49/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6680 - val_loss: 0.6809 - val_accuracy: 0.6260\n",
            "Epoch 50/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6680 - val_loss: 0.6807 - val_accuracy: 0.6260\n",
            "Epoch 51/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6680 - val_loss: 0.6806 - val_accuracy: 0.6260\n",
            "Epoch 52/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6680 - val_loss: 0.6805 - val_accuracy: 0.6260\n",
            "Epoch 53/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6680 - val_loss: 0.6804 - val_accuracy: 0.6260\n",
            "Epoch 54/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6680 - val_loss: 0.6803 - val_accuracy: 0.6260\n",
            "Epoch 55/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6680 - val_loss: 0.6802 - val_accuracy: 0.6260\n",
            "Epoch 56/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6680 - val_loss: 0.6802 - val_accuracy: 0.6260\n",
            "Epoch 57/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6680 - val_loss: 0.6801 - val_accuracy: 0.6260\n",
            "Epoch 58/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6680 - val_loss: 0.6800 - val_accuracy: 0.6260\n",
            "Epoch 59/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6680 - val_loss: 0.6799 - val_accuracy: 0.6260\n",
            "Epoch 60/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6680 - val_loss: 0.6799 - val_accuracy: 0.6260\n",
            "Epoch 61/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6680 - val_loss: 0.6798 - val_accuracy: 0.6260\n",
            "Epoch 62/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6680 - val_loss: 0.6797 - val_accuracy: 0.6260\n",
            "Epoch 63/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6680 - val_loss: 0.6796 - val_accuracy: 0.6260\n",
            "Epoch 64/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6680 - val_loss: 0.6796 - val_accuracy: 0.6260\n",
            "Epoch 65/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6680 - val_loss: 0.6795 - val_accuracy: 0.6260\n",
            "Epoch 66/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6680 - val_loss: 0.6794 - val_accuracy: 0.6260\n",
            "Epoch 67/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6680 - val_loss: 0.6794 - val_accuracy: 0.6260\n",
            "Epoch 68/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6680 - val_loss: 0.6793 - val_accuracy: 0.6260\n",
            "Epoch 69/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6680 - val_loss: 0.6792 - val_accuracy: 0.6260\n",
            "Epoch 70/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6680 - val_loss: 0.6792 - val_accuracy: 0.6260\n",
            "Epoch 71/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6680 - val_loss: 0.6791 - val_accuracy: 0.6260\n",
            "Epoch 72/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6680 - val_loss: 0.6791 - val_accuracy: 0.6260\n",
            "Epoch 73/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6680 - val_loss: 0.6790 - val_accuracy: 0.6260\n",
            "Epoch 74/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6680 - val_loss: 0.6790 - val_accuracy: 0.6260\n",
            "Epoch 75/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6680 - val_loss: 0.6789 - val_accuracy: 0.6260\n",
            "Epoch 76/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6680 - val_loss: 0.6788 - val_accuracy: 0.6260\n",
            "Epoch 77/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6680 - val_loss: 0.6788 - val_accuracy: 0.6260\n",
            "Epoch 78/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6680 - val_loss: 0.6787 - val_accuracy: 0.6260\n",
            "Epoch 79/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6680 - val_loss: 0.6787 - val_accuracy: 0.6260\n",
            "Epoch 80/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6680 - val_loss: 0.6786 - val_accuracy: 0.6260\n",
            "Epoch 81/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6680 - val_loss: 0.6786 - val_accuracy: 0.6260\n",
            "Epoch 82/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6680 - val_loss: 0.6785 - val_accuracy: 0.6260\n",
            "Epoch 83/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6680 - val_loss: 0.6785 - val_accuracy: 0.6260\n",
            "Epoch 84/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6680 - val_loss: 0.6784 - val_accuracy: 0.6260\n",
            "Epoch 85/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6680 - val_loss: 0.6784 - val_accuracy: 0.6260\n",
            "Epoch 86/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6680 - val_loss: 0.6783 - val_accuracy: 0.6260\n",
            "Epoch 87/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6680 - val_loss: 0.6783 - val_accuracy: 0.6260\n",
            "Epoch 88/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6680 - val_loss: 0.6782 - val_accuracy: 0.6260\n",
            "Epoch 89/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6680 - val_loss: 0.6782 - val_accuracy: 0.6260\n",
            "Epoch 90/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6680 - val_loss: 0.6781 - val_accuracy: 0.6260\n",
            "Epoch 91/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6680 - val_loss: 0.6781 - val_accuracy: 0.6260\n",
            "Epoch 92/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6680 - val_loss: 0.6780 - val_accuracy: 0.6260\n",
            "Epoch 93/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6680 - val_loss: 0.6780 - val_accuracy: 0.6260\n",
            "Epoch 94/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6680 - val_loss: 0.6779 - val_accuracy: 0.6260\n",
            "Epoch 95/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6680 - val_loss: 0.6779 - val_accuracy: 0.6260\n",
            "Epoch 96/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6680 - val_loss: 0.6778 - val_accuracy: 0.6260\n",
            "Epoch 97/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6680 - val_loss: 0.6778 - val_accuracy: 0.6260\n",
            "Epoch 98/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6680 - val_loss: 0.6778 - val_accuracy: 0.6260\n",
            "Epoch 99/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6680 - val_loss: 0.6777 - val_accuracy: 0.6260\n",
            "Epoch 100/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6680 - val_loss: 0.6777 - val_accuracy: 0.6260\n",
            "Epoch 101/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6680 - val_loss: 0.6776 - val_accuracy: 0.6260\n",
            "Epoch 102/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6680 - val_loss: 0.6776 - val_accuracy: 0.6260\n",
            "Epoch 103/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6680 - val_loss: 0.6775 - val_accuracy: 0.6260\n",
            "Epoch 104/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6680 - val_loss: 0.6775 - val_accuracy: 0.6260\n",
            "Epoch 105/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6680 - val_loss: 0.6774 - val_accuracy: 0.6260\n",
            "Epoch 106/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6680 - val_loss: 0.6774 - val_accuracy: 0.6260\n",
            "Epoch 107/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6680 - val_loss: 0.6773 - val_accuracy: 0.6260\n",
            "Epoch 108/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6680 - val_loss: 0.6773 - val_accuracy: 0.6260\n",
            "Epoch 109/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6680 - val_loss: 0.6772 - val_accuracy: 0.6260\n",
            "Epoch 110/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6680 - val_loss: 0.6772 - val_accuracy: 0.6260\n",
            "Epoch 111/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6680 - val_loss: 0.6771 - val_accuracy: 0.6260\n",
            "Epoch 112/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6680 - val_loss: 0.6771 - val_accuracy: 0.6260\n",
            "Epoch 113/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6680 - val_loss: 0.6770 - val_accuracy: 0.6260\n",
            "Epoch 114/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6680 - val_loss: 0.6769 - val_accuracy: 0.6260\n",
            "Epoch 115/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6680 - val_loss: 0.6769 - val_accuracy: 0.6260\n",
            "Epoch 116/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6680 - val_loss: 0.6768 - val_accuracy: 0.6260\n",
            "Epoch 117/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6680 - val_loss: 0.6768 - val_accuracy: 0.6260\n",
            "Epoch 118/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6680 - val_loss: 0.6767 - val_accuracy: 0.6260\n",
            "Epoch 119/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6680 - val_loss: 0.6767 - val_accuracy: 0.6260\n",
            "Epoch 120/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6680 - val_loss: 0.6766 - val_accuracy: 0.6260\n",
            "Epoch 121/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6680 - val_loss: 0.6766 - val_accuracy: 0.6260\n",
            "Epoch 122/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6680 - val_loss: 0.6765 - val_accuracy: 0.6260\n",
            "Epoch 123/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6680 - val_loss: 0.6765 - val_accuracy: 0.6260\n",
            "Epoch 124/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6680 - val_loss: 0.6764 - val_accuracy: 0.6260\n",
            "Epoch 125/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6680 - val_loss: 0.6764 - val_accuracy: 0.6260\n",
            "Epoch 126/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6680 - val_loss: 0.6763 - val_accuracy: 0.6260\n",
            "Epoch 127/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6680 - val_loss: 0.6763 - val_accuracy: 0.6260\n",
            "Epoch 128/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.6680 - val_loss: 0.6762 - val_accuracy: 0.6260\n",
            "Epoch 129/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6680 - val_loss: 0.6762 - val_accuracy: 0.6260\n",
            "Epoch 130/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6680 - val_loss: 0.6761 - val_accuracy: 0.6260\n",
            "Epoch 131/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6680 - val_loss: 0.6761 - val_accuracy: 0.6260\n",
            "Epoch 132/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.6680 - val_loss: 0.6760 - val_accuracy: 0.6260\n",
            "Epoch 133/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6680 - val_loss: 0.6760 - val_accuracy: 0.6260\n",
            "Epoch 134/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6680 - val_loss: 0.6759 - val_accuracy: 0.6260\n",
            "Epoch 135/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6680 - val_loss: 0.6759 - val_accuracy: 0.6260\n",
            "Epoch 136/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6680 - val_loss: 0.6758 - val_accuracy: 0.6260\n",
            "Epoch 137/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6680 - val_loss: 0.6758 - val_accuracy: 0.6260\n",
            "Epoch 138/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6680 - val_loss: 0.6757 - val_accuracy: 0.6260\n",
            "Epoch 139/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6680 - val_loss: 0.6756 - val_accuracy: 0.6260\n",
            "Epoch 140/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6680 - val_loss: 0.6756 - val_accuracy: 0.6260\n",
            "Epoch 141/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6680 - val_loss: 0.6755 - val_accuracy: 0.6260\n",
            "Epoch 142/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6680 - val_loss: 0.6755 - val_accuracy: 0.6260\n",
            "Epoch 143/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6680 - val_loss: 0.6754 - val_accuracy: 0.6260\n",
            "Epoch 144/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6680 - val_loss: 0.6753 - val_accuracy: 0.6260\n",
            "Epoch 145/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6680 - val_loss: 0.6753 - val_accuracy: 0.6260\n",
            "Epoch 146/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6680 - val_loss: 0.6752 - val_accuracy: 0.6260\n",
            "Epoch 147/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6680 - val_loss: 0.6751 - val_accuracy: 0.6260\n",
            "Epoch 148/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6680 - val_loss: 0.6751 - val_accuracy: 0.6260\n",
            "Epoch 149/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6680 - val_loss: 0.6750 - val_accuracy: 0.6260\n",
            "Epoch 150/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6680 - val_loss: 0.6750 - val_accuracy: 0.6260\n",
            "Epoch 151/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6680 - val_loss: 0.6749 - val_accuracy: 0.6260\n",
            "Epoch 152/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6680 - val_loss: 0.6748 - val_accuracy: 0.6260\n",
            "Epoch 153/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.6680 - val_loss: 0.6748 - val_accuracy: 0.6260\n",
            "Epoch 154/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6680 - val_loss: 0.6747 - val_accuracy: 0.6260\n",
            "Epoch 155/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6680 - val_loss: 0.6746 - val_accuracy: 0.6260\n",
            "Epoch 156/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.6680 - val_loss: 0.6746 - val_accuracy: 0.6260\n",
            "Epoch 157/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.6680 - val_loss: 0.6745 - val_accuracy: 0.6260\n",
            "Epoch 158/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.6680 - val_loss: 0.6744 - val_accuracy: 0.6260\n",
            "Epoch 159/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6680 - val_loss: 0.6744 - val_accuracy: 0.6260\n",
            "Epoch 160/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6680 - val_loss: 0.6743 - val_accuracy: 0.6260\n",
            "Epoch 161/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6680 - val_loss: 0.6742 - val_accuracy: 0.6260\n",
            "Epoch 162/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6680 - val_loss: 0.6741 - val_accuracy: 0.6260\n",
            "Epoch 163/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6680 - val_loss: 0.6741 - val_accuracy: 0.6260\n",
            "Epoch 164/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6680 - val_loss: 0.6740 - val_accuracy: 0.6260\n",
            "Epoch 165/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6680 - val_loss: 0.6739 - val_accuracy: 0.6260\n",
            "Epoch 166/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.6680 - val_loss: 0.6739 - val_accuracy: 0.6260\n",
            "Epoch 167/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.6680 - val_loss: 0.6738 - val_accuracy: 0.6260\n",
            "Epoch 168/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6680 - val_loss: 0.6738 - val_accuracy: 0.6260\n",
            "Epoch 169/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6680 - val_loss: 0.6737 - val_accuracy: 0.6260\n",
            "Epoch 170/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6680 - val_loss: 0.6736 - val_accuracy: 0.6260\n",
            "Epoch 171/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6680 - val_loss: 0.6735 - val_accuracy: 0.6260\n",
            "Epoch 172/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.6680 - val_loss: 0.6735 - val_accuracy: 0.6260\n",
            "Epoch 173/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6680 - val_loss: 0.6734 - val_accuracy: 0.6260\n",
            "Epoch 174/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6680 - val_loss: 0.6733 - val_accuracy: 0.6260\n",
            "Epoch 175/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6680 - val_loss: 0.6733 - val_accuracy: 0.6260\n",
            "Epoch 176/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6680 - val_loss: 0.6732 - val_accuracy: 0.6260\n",
            "Epoch 177/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.6680 - val_loss: 0.6731 - val_accuracy: 0.6260\n",
            "Epoch 178/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.6680 - val_loss: 0.6731 - val_accuracy: 0.6260\n",
            "Epoch 179/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6680 - val_loss: 0.6730 - val_accuracy: 0.6260\n",
            "Epoch 180/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6680 - val_loss: 0.6730 - val_accuracy: 0.6260\n",
            "Epoch 181/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6680 - val_loss: 0.6729 - val_accuracy: 0.6260\n",
            "Epoch 182/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6680 - val_loss: 0.6728 - val_accuracy: 0.6260\n",
            "Epoch 183/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6680 - val_loss: 0.6728 - val_accuracy: 0.6260\n",
            "Epoch 184/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6680 - val_loss: 0.6727 - val_accuracy: 0.6260\n",
            "Epoch 185/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.6680 - val_loss: 0.6726 - val_accuracy: 0.6260\n",
            "Epoch 186/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6680 - val_loss: 0.6726 - val_accuracy: 0.6260\n",
            "Epoch 187/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6680 - val_loss: 0.6725 - val_accuracy: 0.6260\n",
            "Epoch 188/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6680 - val_loss: 0.6724 - val_accuracy: 0.6260\n",
            "Epoch 189/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6680 - val_loss: 0.6724 - val_accuracy: 0.6260\n",
            "Epoch 190/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6680 - val_loss: 0.6723 - val_accuracy: 0.6260\n",
            "Epoch 191/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6680 - val_loss: 0.6722 - val_accuracy: 0.6260\n",
            "Epoch 192/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.6680 - val_loss: 0.6722 - val_accuracy: 0.6260\n",
            "Epoch 193/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.6680 - val_loss: 0.6721 - val_accuracy: 0.6260\n",
            "Epoch 194/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6680 - val_loss: 0.6720 - val_accuracy: 0.6260\n",
            "Epoch 195/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6680 - val_loss: 0.6719 - val_accuracy: 0.6260\n",
            "Epoch 196/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6680 - val_loss: 0.6719 - val_accuracy: 0.6260\n",
            "Epoch 197/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6680 - val_loss: 0.6718 - val_accuracy: 0.6260\n",
            "Epoch 198/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6680 - val_loss: 0.6718 - val_accuracy: 0.6260\n",
            "Epoch 199/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6680 - val_loss: 0.6717 - val_accuracy: 0.6260\n",
            "Epoch 200/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6680 - val_loss: 0.6716 - val_accuracy: 0.6260\n",
            "Epoch 201/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6680 - val_loss: 0.6715 - val_accuracy: 0.6260\n",
            "Epoch 202/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6680 - val_loss: 0.6715 - val_accuracy: 0.6260\n",
            "Epoch 203/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6680 - val_loss: 0.6714 - val_accuracy: 0.6260\n",
            "Epoch 204/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6680 - val_loss: 0.6713 - val_accuracy: 0.6260\n",
            "Epoch 205/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6680 - val_loss: 0.6713 - val_accuracy: 0.6260\n",
            "Epoch 206/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6680 - val_loss: 0.6712 - val_accuracy: 0.6260\n",
            "Epoch 207/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6680 - val_loss: 0.6711 - val_accuracy: 0.6260\n",
            "Epoch 208/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6680 - val_loss: 0.6710 - val_accuracy: 0.6260\n",
            "Epoch 209/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6680 - val_loss: 0.6710 - val_accuracy: 0.6260\n",
            "Epoch 210/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6680 - val_loss: 0.6709 - val_accuracy: 0.6260\n",
            "Epoch 211/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6680 - val_loss: 0.6708 - val_accuracy: 0.6260\n",
            "Epoch 212/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6680 - val_loss: 0.6707 - val_accuracy: 0.6260\n",
            "Epoch 213/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6680 - val_loss: 0.6707 - val_accuracy: 0.6260\n",
            "Epoch 214/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6680 - val_loss: 0.6706 - val_accuracy: 0.6260\n",
            "Epoch 215/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6680 - val_loss: 0.6705 - val_accuracy: 0.6260\n",
            "Epoch 216/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6680 - val_loss: 0.6705 - val_accuracy: 0.6260\n",
            "Epoch 217/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6680 - val_loss: 0.6704 - val_accuracy: 0.6260\n",
            "Epoch 218/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6680 - val_loss: 0.6703 - val_accuracy: 0.6260\n",
            "Epoch 219/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6680 - val_loss: 0.6703 - val_accuracy: 0.6260\n",
            "Epoch 220/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6680 - val_loss: 0.6702 - val_accuracy: 0.6260\n",
            "Epoch 221/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6680 - val_loss: 0.6701 - val_accuracy: 0.6260\n",
            "Epoch 222/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6680 - val_loss: 0.6701 - val_accuracy: 0.6260\n",
            "Epoch 223/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6680 - val_loss: 0.6700 - val_accuracy: 0.6260\n",
            "Epoch 224/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6680 - val_loss: 0.6700 - val_accuracy: 0.6260\n",
            "Epoch 225/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6680 - val_loss: 0.6699 - val_accuracy: 0.6260\n",
            "Epoch 226/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6680 - val_loss: 0.6698 - val_accuracy: 0.6260\n",
            "Epoch 227/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6680 - val_loss: 0.6698 - val_accuracy: 0.6260\n",
            "Epoch 228/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6680 - val_loss: 0.6697 - val_accuracy: 0.6260\n",
            "Epoch 229/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 230/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 231/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6680 - val_loss: 0.6695 - val_accuracy: 0.6260\n",
            "Epoch 232/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6680 - val_loss: 0.6694 - val_accuracy: 0.6260\n",
            "Epoch 233/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6680 - val_loss: 0.6694 - val_accuracy: 0.6260\n",
            "Epoch 234/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6680 - val_loss: 0.6693 - val_accuracy: 0.6260\n",
            "Epoch 235/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6680 - val_loss: 0.6692 - val_accuracy: 0.6260\n",
            "Epoch 236/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6680 - val_loss: 0.6691 - val_accuracy: 0.6260\n",
            "Epoch 237/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6680 - val_loss: 0.6691 - val_accuracy: 0.6260\n",
            "Epoch 238/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6680 - val_loss: 0.6690 - val_accuracy: 0.6260\n",
            "Epoch 239/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6680 - val_loss: 0.6690 - val_accuracy: 0.6260\n",
            "Epoch 240/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6680 - val_loss: 0.6689 - val_accuracy: 0.6260\n",
            "Epoch 241/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6680 - val_loss: 0.6688 - val_accuracy: 0.6260\n",
            "Epoch 242/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6680 - val_loss: 0.6688 - val_accuracy: 0.6260\n",
            "Epoch 243/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6680 - val_loss: 0.6687 - val_accuracy: 0.6260\n",
            "Epoch 244/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6680 - val_loss: 0.6686 - val_accuracy: 0.6260\n",
            "Epoch 245/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6680 - val_loss: 0.6686 - val_accuracy: 0.6260\n",
            "Epoch 246/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6680 - val_loss: 0.6685 - val_accuracy: 0.6260\n",
            "Epoch 247/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6680 - val_loss: 0.6684 - val_accuracy: 0.6260\n",
            "Epoch 248/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6680 - val_loss: 0.6684 - val_accuracy: 0.6260\n",
            "Epoch 249/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6680 - val_loss: 0.6683 - val_accuracy: 0.6260\n",
            "Epoch 250/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6680 - val_loss: 0.6682 - val_accuracy: 0.6260\n",
            "Epoch 251/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6680 - val_loss: 0.6682 - val_accuracy: 0.6260\n",
            "Epoch 252/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6680 - val_loss: 0.6681 - val_accuracy: 0.6260\n",
            "Epoch 253/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6680 - val_loss: 0.6680 - val_accuracy: 0.6260\n",
            "Epoch 254/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6680 - val_loss: 0.6680 - val_accuracy: 0.6260\n",
            "Epoch 255/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6680 - val_loss: 0.6679 - val_accuracy: 0.6260\n",
            "Epoch 256/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6680 - val_loss: 0.6678 - val_accuracy: 0.6260\n",
            "Epoch 257/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6680 - val_loss: 0.6678 - val_accuracy: 0.6260\n",
            "Epoch 258/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6680 - val_loss: 0.6677 - val_accuracy: 0.6260\n",
            "Epoch 259/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6680 - val_loss: 0.6676 - val_accuracy: 0.6260\n",
            "Epoch 260/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.6680 - val_loss: 0.6676 - val_accuracy: 0.6260\n",
            "Epoch 261/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.6680 - val_loss: 0.6675 - val_accuracy: 0.6260\n",
            "Epoch 262/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6680 - val_loss: 0.6675 - val_accuracy: 0.6260\n",
            "Epoch 263/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6680 - val_loss: 0.6674 - val_accuracy: 0.6260\n",
            "Epoch 264/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6680 - val_loss: 0.6673 - val_accuracy: 0.6260\n",
            "Epoch 265/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6680 - val_loss: 0.6673 - val_accuracy: 0.6260\n",
            "Epoch 266/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6680 - val_loss: 0.6672 - val_accuracy: 0.6260\n",
            "Epoch 267/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.6680 - val_loss: 0.6671 - val_accuracy: 0.6260\n",
            "Epoch 268/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6680 - val_loss: 0.6671 - val_accuracy: 0.6260\n",
            "Epoch 269/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6680 - val_loss: 0.6670 - val_accuracy: 0.6260\n",
            "Epoch 270/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6680 - val_loss: 0.6670 - val_accuracy: 0.6260\n",
            "Epoch 271/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6680 - val_loss: 0.6669 - val_accuracy: 0.6260\n",
            "Epoch 272/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6680 - val_loss: 0.6668 - val_accuracy: 0.6260\n",
            "Epoch 273/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6680 - val_loss: 0.6668 - val_accuracy: 0.6260\n",
            "Epoch 274/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6680 - val_loss: 0.6667 - val_accuracy: 0.6260\n",
            "Epoch 275/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6680 - val_loss: 0.6667 - val_accuracy: 0.6260\n",
            "Epoch 276/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6680 - val_loss: 0.6666 - val_accuracy: 0.6260\n",
            "Epoch 277/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6680 - val_loss: 0.6666 - val_accuracy: 0.6260\n",
            "Epoch 278/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6680 - val_loss: 0.6665 - val_accuracy: 0.6260\n",
            "Epoch 279/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6680 - val_loss: 0.6664 - val_accuracy: 0.6260\n",
            "Epoch 280/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6680 - val_loss: 0.6664 - val_accuracy: 0.6260\n",
            "Epoch 281/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6680 - val_loss: 0.6663 - val_accuracy: 0.6260\n",
            "Epoch 282/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6680 - val_loss: 0.6663 - val_accuracy: 0.6260\n",
            "Epoch 283/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6680 - val_loss: 0.6662 - val_accuracy: 0.6260\n",
            "Epoch 284/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6680 - val_loss: 0.6662 - val_accuracy: 0.6260\n",
            "Epoch 285/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6680 - val_loss: 0.6661 - val_accuracy: 0.6260\n",
            "Epoch 286/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6680 - val_loss: 0.6660 - val_accuracy: 0.6260\n",
            "Epoch 287/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6680 - val_loss: 0.6660 - val_accuracy: 0.6260\n",
            "Epoch 288/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6680 - val_loss: 0.6659 - val_accuracy: 0.6260\n",
            "Epoch 289/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6680 - val_loss: 0.6659 - val_accuracy: 0.6260\n",
            "Epoch 290/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6680 - val_loss: 0.6658 - val_accuracy: 0.6260\n",
            "Epoch 291/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6680 - val_loss: 0.6658 - val_accuracy: 0.6260\n",
            "Epoch 292/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6680 - val_loss: 0.6657 - val_accuracy: 0.6260\n",
            "Epoch 293/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6680 - val_loss: 0.6656 - val_accuracy: 0.6260\n",
            "Epoch 294/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6680 - val_loss: 0.6656 - val_accuracy: 0.6260\n",
            "Epoch 295/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6680 - val_loss: 0.6655 - val_accuracy: 0.6260\n",
            "Epoch 296/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6680 - val_loss: 0.6655 - val_accuracy: 0.6260\n",
            "Epoch 297/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6680 - val_loss: 0.6654 - val_accuracy: 0.6260\n",
            "Epoch 298/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6680 - val_loss: 0.6654 - val_accuracy: 0.6260\n",
            "Epoch 299/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6680 - val_loss: 0.6653 - val_accuracy: 0.6260\n",
            "Epoch 300/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6680 - val_loss: 0.6652 - val_accuracy: 0.6260\n",
            "Epoch 301/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6680 - val_loss: 0.6652 - val_accuracy: 0.6260\n",
            "Epoch 302/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6680 - val_loss: 0.6651 - val_accuracy: 0.6260\n",
            "Epoch 303/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6680 - val_loss: 0.6651 - val_accuracy: 0.6260\n",
            "Epoch 304/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6680 - val_loss: 0.6650 - val_accuracy: 0.6260\n",
            "Epoch 305/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6680 - val_loss: 0.6649 - val_accuracy: 0.6260\n",
            "Epoch 306/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6680 - val_loss: 0.6649 - val_accuracy: 0.6260\n",
            "Epoch 307/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6680 - val_loss: 0.6648 - val_accuracy: 0.6260\n",
            "Epoch 308/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6680 - val_loss: 0.6648 - val_accuracy: 0.6260\n",
            "Epoch 309/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6680 - val_loss: 0.6647 - val_accuracy: 0.6260\n",
            "Epoch 310/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6680 - val_loss: 0.6647 - val_accuracy: 0.6260\n",
            "Epoch 311/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6680 - val_loss: 0.6646 - val_accuracy: 0.6260\n",
            "Epoch 312/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6680 - val_loss: 0.6646 - val_accuracy: 0.6260\n",
            "Epoch 313/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6680 - val_loss: 0.6645 - val_accuracy: 0.6260\n",
            "Epoch 314/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6680 - val_loss: 0.6644 - val_accuracy: 0.6260\n",
            "Epoch 315/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6680 - val_loss: 0.6644 - val_accuracy: 0.6260\n",
            "Epoch 316/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6680 - val_loss: 0.6643 - val_accuracy: 0.6260\n",
            "Epoch 317/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6680 - val_loss: 0.6643 - val_accuracy: 0.6260\n",
            "Epoch 318/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6680 - val_loss: 0.6642 - val_accuracy: 0.6260\n",
            "Epoch 319/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6680 - val_loss: 0.6642 - val_accuracy: 0.6260\n",
            "Epoch 320/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6680 - val_loss: 0.6641 - val_accuracy: 0.6260\n",
            "Epoch 321/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.6680 - val_loss: 0.6641 - val_accuracy: 0.6260\n",
            "Epoch 322/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6680 - val_loss: 0.6640 - val_accuracy: 0.6260\n",
            "Epoch 323/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6680 - val_loss: 0.6640 - val_accuracy: 0.6260\n",
            "Epoch 324/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6680 - val_loss: 0.6639 - val_accuracy: 0.6260\n",
            "Epoch 325/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6680 - val_loss: 0.6638 - val_accuracy: 0.6260\n",
            "Epoch 326/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6680 - val_loss: 0.6638 - val_accuracy: 0.6260\n",
            "Epoch 327/1000\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.6304 - accuracy: 0.6680 - val_loss: 0.6637 - val_accuracy: 0.6260\n",
            "Epoch 328/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.6680 - val_loss: 0.6637 - val_accuracy: 0.6260\n",
            "Epoch 329/1000\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6680 - val_loss: 0.6636 - val_accuracy: 0.6260\n",
            "Epoch 330/1000\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6680 - val_loss: 0.6636 - val_accuracy: 0.6260\n",
            "Epoch 331/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6680 - val_loss: 0.6635 - val_accuracy: 0.6260\n",
            "Epoch 332/1000\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.6301 - accuracy: 0.6680 - val_loss: 0.6635 - val_accuracy: 0.6260\n",
            "Epoch 333/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6680 - val_loss: 0.6634 - val_accuracy: 0.6260\n",
            "Epoch 334/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6680 - val_loss: 0.6634 - val_accuracy: 0.6260\n",
            "Epoch 335/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6680 - val_loss: 0.6633 - val_accuracy: 0.6260\n",
            "Epoch 336/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6680 - val_loss: 0.6633 - val_accuracy: 0.6260\n",
            "Epoch 337/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6680 - val_loss: 0.6632 - val_accuracy: 0.6260\n",
            "Epoch 338/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6680 - val_loss: 0.6632 - val_accuracy: 0.6260\n",
            "Epoch 339/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6680 - val_loss: 0.6631 - val_accuracy: 0.6260\n",
            "Epoch 340/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6680 - val_loss: 0.6631 - val_accuracy: 0.6260\n",
            "Epoch 341/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6680 - val_loss: 0.6630 - val_accuracy: 0.6260\n",
            "Epoch 342/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6680 - val_loss: 0.6630 - val_accuracy: 0.6260\n",
            "Epoch 343/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6680 - val_loss: 0.6629 - val_accuracy: 0.6260\n",
            "Epoch 344/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6680 - val_loss: 0.6629 - val_accuracy: 0.6260\n",
            "Epoch 345/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6680 - val_loss: 0.6628 - val_accuracy: 0.6260\n",
            "Epoch 346/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6680 - val_loss: 0.6628 - val_accuracy: 0.6260\n",
            "Epoch 347/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6680 - val_loss: 0.6627 - val_accuracy: 0.6260\n",
            "Epoch 348/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6680 - val_loss: 0.6626 - val_accuracy: 0.6260\n",
            "Epoch 349/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6680 - val_loss: 0.6626 - val_accuracy: 0.6260\n",
            "Epoch 350/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6680 - val_loss: 0.6625 - val_accuracy: 0.6260\n",
            "Epoch 351/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6680 - val_loss: 0.6625 - val_accuracy: 0.6260\n",
            "Epoch 352/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6680 - val_loss: 0.6624 - val_accuracy: 0.6260\n",
            "Epoch 353/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6680 - val_loss: 0.6624 - val_accuracy: 0.6260\n",
            "Epoch 354/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6680 - val_loss: 0.6623 - val_accuracy: 0.6260\n",
            "Epoch 355/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6680 - val_loss: 0.6623 - val_accuracy: 0.6260\n",
            "Epoch 356/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6680 - val_loss: 0.6622 - val_accuracy: 0.6260\n",
            "Epoch 357/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6680 - val_loss: 0.6622 - val_accuracy: 0.6260\n",
            "Epoch 358/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6680 - val_loss: 0.6621 - val_accuracy: 0.6260\n",
            "Epoch 359/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6680 - val_loss: 0.6621 - val_accuracy: 0.6260\n",
            "Epoch 360/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6680 - val_loss: 0.6620 - val_accuracy: 0.6260\n",
            "Epoch 361/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6680 - val_loss: 0.6620 - val_accuracy: 0.6260\n",
            "Epoch 362/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6680 - val_loss: 0.6619 - val_accuracy: 0.6260\n",
            "Epoch 363/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6680 - val_loss: 0.6619 - val_accuracy: 0.6260\n",
            "Epoch 364/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6680 - val_loss: 0.6618 - val_accuracy: 0.6260\n",
            "Epoch 365/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6680 - val_loss: 0.6618 - val_accuracy: 0.6260\n",
            "Epoch 366/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6680 - val_loss: 0.6617 - val_accuracy: 0.6260\n",
            "Epoch 367/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6680 - val_loss: 0.6617 - val_accuracy: 0.6260\n",
            "Epoch 368/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6680 - val_loss: 0.6616 - val_accuracy: 0.6260\n",
            "Epoch 369/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6680 - val_loss: 0.6616 - val_accuracy: 0.6260\n",
            "Epoch 370/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6680 - val_loss: 0.6615 - val_accuracy: 0.6260\n",
            "Epoch 371/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6680 - val_loss: 0.6615 - val_accuracy: 0.6260\n",
            "Epoch 372/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6680 - val_loss: 0.6614 - val_accuracy: 0.6260\n",
            "Epoch 373/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6680 - val_loss: 0.6614 - val_accuracy: 0.6260\n",
            "Epoch 374/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6680 - val_loss: 0.6613 - val_accuracy: 0.6260\n",
            "Epoch 375/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6680 - val_loss: 0.6613 - val_accuracy: 0.6260\n",
            "Epoch 376/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6680 - val_loss: 0.6612 - val_accuracy: 0.6260\n",
            "Epoch 377/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6680 - val_loss: 0.6612 - val_accuracy: 0.6260\n",
            "Epoch 378/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6680 - val_loss: 0.6611 - val_accuracy: 0.6260\n",
            "Epoch 379/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6680 - val_loss: 0.6611 - val_accuracy: 0.6260\n",
            "Epoch 380/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6680 - val_loss: 0.6610 - val_accuracy: 0.6260\n",
            "Epoch 381/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6680 - val_loss: 0.6610 - val_accuracy: 0.6260\n",
            "Epoch 382/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6680 - val_loss: 0.6609 - val_accuracy: 0.6260\n",
            "Epoch 383/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6680 - val_loss: 0.6609 - val_accuracy: 0.6260\n",
            "Epoch 384/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6680 - val_loss: 0.6608 - val_accuracy: 0.6260\n",
            "Epoch 385/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6680 - val_loss: 0.6608 - val_accuracy: 0.6260\n",
            "Epoch 386/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6680 - val_loss: 0.6607 - val_accuracy: 0.6260\n",
            "Epoch 387/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6680 - val_loss: 0.6607 - val_accuracy: 0.6260\n",
            "Epoch 388/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6680 - val_loss: 0.6606 - val_accuracy: 0.6260\n",
            "Epoch 389/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6680 - val_loss: 0.6606 - val_accuracy: 0.6260\n",
            "Epoch 390/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6680 - val_loss: 0.6605 - val_accuracy: 0.6260\n",
            "Epoch 391/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6680 - val_loss: 0.6605 - val_accuracy: 0.6260\n",
            "Epoch 392/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6680 - val_loss: 0.6604 - val_accuracy: 0.6260\n",
            "Epoch 393/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6680 - val_loss: 0.6604 - val_accuracy: 0.6260\n",
            "Epoch 394/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6680 - val_loss: 0.6603 - val_accuracy: 0.6260\n",
            "Epoch 395/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6680 - val_loss: 0.6603 - val_accuracy: 0.6260\n",
            "Epoch 396/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6680 - val_loss: 0.6602 - val_accuracy: 0.6260\n",
            "Epoch 397/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6680 - val_loss: 0.6602 - val_accuracy: 0.6260\n",
            "Epoch 398/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6680 - val_loss: 0.6601 - val_accuracy: 0.6260\n",
            "Epoch 399/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6680 - val_loss: 0.6601 - val_accuracy: 0.6260\n",
            "Epoch 400/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6680 - val_loss: 0.6600 - val_accuracy: 0.6260\n",
            "Epoch 401/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6680 - val_loss: 0.6600 - val_accuracy: 0.6260\n",
            "Epoch 402/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6680 - val_loss: 0.6599 - val_accuracy: 0.6260\n",
            "Epoch 403/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6680 - val_loss: 0.6599 - val_accuracy: 0.6260\n",
            "Epoch 404/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6680 - val_loss: 0.6598 - val_accuracy: 0.6260\n",
            "Epoch 405/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6680 - val_loss: 0.6598 - val_accuracy: 0.6260\n",
            "Epoch 406/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6680 - val_loss: 0.6597 - val_accuracy: 0.6260\n",
            "Epoch 407/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6680 - val_loss: 0.6597 - val_accuracy: 0.6260\n",
            "Epoch 408/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6680 - val_loss: 0.6596 - val_accuracy: 0.6260\n",
            "Epoch 409/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6680 - val_loss: 0.6595 - val_accuracy: 0.6260\n",
            "Epoch 410/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6680 - val_loss: 0.6595 - val_accuracy: 0.6260\n",
            "Epoch 411/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6680 - val_loss: 0.6594 - val_accuracy: 0.6260\n",
            "Epoch 412/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6680 - val_loss: 0.6594 - val_accuracy: 0.6260\n",
            "Epoch 413/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6680 - val_loss: 0.6593 - val_accuracy: 0.6260\n",
            "Epoch 414/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6680 - val_loss: 0.6593 - val_accuracy: 0.6260\n",
            "Epoch 415/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6680 - val_loss: 0.6592 - val_accuracy: 0.6260\n",
            "Epoch 416/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6680 - val_loss: 0.6592 - val_accuracy: 0.6260\n",
            "Epoch 417/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6680 - val_loss: 0.6591 - val_accuracy: 0.6260\n",
            "Epoch 418/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6680 - val_loss: 0.6590 - val_accuracy: 0.6260\n",
            "Epoch 419/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6680 - val_loss: 0.6590 - val_accuracy: 0.6260\n",
            "Epoch 420/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6680 - val_loss: 0.6589 - val_accuracy: 0.6260\n",
            "Epoch 421/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6680 - val_loss: 0.6589 - val_accuracy: 0.6260\n",
            "Epoch 422/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6680 - val_loss: 0.6588 - val_accuracy: 0.6260\n",
            "Epoch 423/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6680 - val_loss: 0.6588 - val_accuracy: 0.6260\n",
            "Epoch 424/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6680 - val_loss: 0.6587 - val_accuracy: 0.6260\n",
            "Epoch 425/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6680 - val_loss: 0.6587 - val_accuracy: 0.6260\n",
            "Epoch 426/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6680 - val_loss: 0.6586 - val_accuracy: 0.6260\n",
            "Epoch 427/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.6680 - val_loss: 0.6585 - val_accuracy: 0.6260\n",
            "Epoch 428/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6680 - val_loss: 0.6585 - val_accuracy: 0.6260\n",
            "Epoch 429/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6680 - val_loss: 0.6584 - val_accuracy: 0.6260\n",
            "Epoch 430/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6680 - val_loss: 0.6584 - val_accuracy: 0.6260\n",
            "Epoch 431/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6680 - val_loss: 0.6583 - val_accuracy: 0.6260\n",
            "Epoch 432/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6680 - val_loss: 0.6583 - val_accuracy: 0.6260\n",
            "Epoch 433/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6680 - val_loss: 0.6582 - val_accuracy: 0.6260\n",
            "Epoch 434/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6680 - val_loss: 0.6582 - val_accuracy: 0.6260\n",
            "Epoch 435/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6680 - val_loss: 0.6581 - val_accuracy: 0.6260\n",
            "Epoch 436/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6680 - val_loss: 0.6581 - val_accuracy: 0.6260\n",
            "Epoch 437/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6680 - val_loss: 0.6580 - val_accuracy: 0.6260\n",
            "Epoch 438/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6680 - val_loss: 0.6579 - val_accuracy: 0.6260\n",
            "Epoch 439/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6680 - val_loss: 0.6579 - val_accuracy: 0.6260\n",
            "Epoch 440/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6680 - val_loss: 0.6578 - val_accuracy: 0.6260\n",
            "Epoch 441/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6680 - val_loss: 0.6578 - val_accuracy: 0.6260\n",
            "Epoch 442/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6680 - val_loss: 0.6577 - val_accuracy: 0.6260\n",
            "Epoch 443/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6680 - val_loss: 0.6577 - val_accuracy: 0.6260\n",
            "Epoch 444/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6680 - val_loss: 0.6577 - val_accuracy: 0.6260\n",
            "Epoch 445/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6680 - val_loss: 0.6576 - val_accuracy: 0.6260\n",
            "Epoch 446/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6680 - val_loss: 0.6576 - val_accuracy: 0.6260\n",
            "Epoch 447/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6680 - val_loss: 0.6575 - val_accuracy: 0.6260\n",
            "Epoch 448/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6680 - val_loss: 0.6574 - val_accuracy: 0.6260\n",
            "Epoch 449/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6680 - val_loss: 0.6574 - val_accuracy: 0.6260\n",
            "Epoch 450/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6680 - val_loss: 0.6574 - val_accuracy: 0.6260\n",
            "Epoch 451/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6680 - val_loss: 0.6573 - val_accuracy: 0.6260\n",
            "Epoch 452/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6680 - val_loss: 0.6572 - val_accuracy: 0.6260\n",
            "Epoch 453/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6680 - val_loss: 0.6572 - val_accuracy: 0.6260\n",
            "Epoch 454/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6680 - val_loss: 0.6571 - val_accuracy: 0.6260\n",
            "Epoch 455/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6680 - val_loss: 0.6571 - val_accuracy: 0.6260\n",
            "Epoch 456/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6680 - val_loss: 0.6570 - val_accuracy: 0.6260\n",
            "Epoch 457/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6680 - val_loss: 0.6570 - val_accuracy: 0.6260\n",
            "Epoch 458/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6680 - val_loss: 0.6569 - val_accuracy: 0.6260\n",
            "Epoch 459/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6680 - val_loss: 0.6568 - val_accuracy: 0.6260\n",
            "Epoch 460/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6680 - val_loss: 0.6568 - val_accuracy: 0.6260\n",
            "Epoch 461/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6680 - val_loss: 0.6567 - val_accuracy: 0.6260\n",
            "Epoch 462/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6680 - val_loss: 0.6567 - val_accuracy: 0.6260\n",
            "Epoch 463/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6680 - val_loss: 0.6566 - val_accuracy: 0.6260\n",
            "Epoch 464/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6680 - val_loss: 0.6566 - val_accuracy: 0.6260\n",
            "Epoch 465/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6680 - val_loss: 0.6565 - val_accuracy: 0.6260\n",
            "Epoch 466/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6680 - val_loss: 0.6565 - val_accuracy: 0.6260\n",
            "Epoch 467/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6680 - val_loss: 0.6564 - val_accuracy: 0.6260\n",
            "Epoch 468/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6680 - val_loss: 0.6564 - val_accuracy: 0.6260\n",
            "Epoch 469/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6680 - val_loss: 0.6563 - val_accuracy: 0.6260\n",
            "Epoch 470/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6680 - val_loss: 0.6562 - val_accuracy: 0.6260\n",
            "Epoch 471/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6680 - val_loss: 0.6562 - val_accuracy: 0.6260\n",
            "Epoch 472/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6680 - val_loss: 0.6561 - val_accuracy: 0.6260\n",
            "Epoch 473/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6680 - val_loss: 0.6561 - val_accuracy: 0.6260\n",
            "Epoch 474/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6680 - val_loss: 0.6560 - val_accuracy: 0.6260\n",
            "Epoch 475/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6680 - val_loss: 0.6560 - val_accuracy: 0.6260\n",
            "Epoch 476/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6680 - val_loss: 0.6559 - val_accuracy: 0.6260\n",
            "Epoch 477/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6680 - val_loss: 0.6559 - val_accuracy: 0.6260\n",
            "Epoch 478/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6680 - val_loss: 0.6558 - val_accuracy: 0.6260\n",
            "Epoch 479/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6680 - val_loss: 0.6557 - val_accuracy: 0.6260\n",
            "Epoch 480/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6680 - val_loss: 0.6557 - val_accuracy: 0.6260\n",
            "Epoch 481/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6680 - val_loss: 0.6556 - val_accuracy: 0.6260\n",
            "Epoch 482/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6680 - val_loss: 0.6556 - val_accuracy: 0.6260\n",
            "Epoch 483/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6680 - val_loss: 0.6555 - val_accuracy: 0.6260\n",
            "Epoch 484/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6680 - val_loss: 0.6555 - val_accuracy: 0.6260\n",
            "Epoch 485/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6680 - val_loss: 0.6554 - val_accuracy: 0.6260\n",
            "Epoch 486/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6680 - val_loss: 0.6553 - val_accuracy: 0.6260\n",
            "Epoch 487/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6680 - val_loss: 0.6553 - val_accuracy: 0.6260\n",
            "Epoch 488/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6680 - val_loss: 0.6552 - val_accuracy: 0.6260\n",
            "Epoch 489/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6680 - val_loss: 0.6552 - val_accuracy: 0.6260\n",
            "Epoch 490/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6680 - val_loss: 0.6551 - val_accuracy: 0.6260\n",
            "Epoch 491/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6680 - val_loss: 0.6551 - val_accuracy: 0.6260\n",
            "Epoch 492/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6680 - val_loss: 0.6550 - val_accuracy: 0.6260\n",
            "Epoch 493/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6680 - val_loss: 0.6550 - val_accuracy: 0.6260\n",
            "Epoch 494/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6680 - val_loss: 0.6549 - val_accuracy: 0.6260\n",
            "Epoch 495/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6680 - val_loss: 0.6549 - val_accuracy: 0.6260\n",
            "Epoch 496/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6680 - val_loss: 0.6548 - val_accuracy: 0.6260\n",
            "Epoch 497/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6680 - val_loss: 0.6548 - val_accuracy: 0.6260\n",
            "Epoch 498/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6680 - val_loss: 0.6547 - val_accuracy: 0.6260\n",
            "Epoch 499/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6680 - val_loss: 0.6546 - val_accuracy: 0.6260\n",
            "Epoch 500/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6680 - val_loss: 0.6546 - val_accuracy: 0.6260\n",
            "Epoch 501/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6680 - val_loss: 0.6545 - val_accuracy: 0.6260\n",
            "Epoch 502/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6680 - val_loss: 0.6545 - val_accuracy: 0.6260\n",
            "Epoch 503/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6680 - val_loss: 0.6544 - val_accuracy: 0.6260\n",
            "Epoch 504/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6680 - val_loss: 0.6543 - val_accuracy: 0.6260\n",
            "Epoch 505/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6680 - val_loss: 0.6543 - val_accuracy: 0.6260\n",
            "Epoch 506/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6680 - val_loss: 0.6542 - val_accuracy: 0.6260\n",
            "Epoch 507/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6680 - val_loss: 0.6542 - val_accuracy: 0.6260\n",
            "Epoch 508/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6680 - val_loss: 0.6541 - val_accuracy: 0.6260\n",
            "Epoch 509/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6680 - val_loss: 0.6541 - val_accuracy: 0.6260\n",
            "Epoch 510/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6680 - val_loss: 0.6540 - val_accuracy: 0.6260\n",
            "Epoch 511/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6680 - val_loss: 0.6539 - val_accuracy: 0.6260\n",
            "Epoch 512/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6680 - val_loss: 0.6539 - val_accuracy: 0.6260\n",
            "Epoch 513/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6680 - val_loss: 0.6538 - val_accuracy: 0.6260\n",
            "Epoch 514/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6680 - val_loss: 0.6538 - val_accuracy: 0.6260\n",
            "Epoch 515/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6680 - val_loss: 0.6537 - val_accuracy: 0.6260\n",
            "Epoch 516/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6680 - val_loss: 0.6536 - val_accuracy: 0.6260\n",
            "Epoch 517/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6680 - val_loss: 0.6536 - val_accuracy: 0.6260\n",
            "Epoch 518/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6680 - val_loss: 0.6535 - val_accuracy: 0.6260\n",
            "Epoch 519/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6680 - val_loss: 0.6534 - val_accuracy: 0.6260\n",
            "Epoch 520/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6680 - val_loss: 0.6534 - val_accuracy: 0.6260\n",
            "Epoch 521/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6680 - val_loss: 0.6533 - val_accuracy: 0.6260\n",
            "Epoch 522/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6680 - val_loss: 0.6533 - val_accuracy: 0.6260\n",
            "Epoch 523/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6680 - val_loss: 0.6532 - val_accuracy: 0.6260\n",
            "Epoch 524/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6680 - val_loss: 0.6531 - val_accuracy: 0.6260\n",
            "Epoch 525/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6680 - val_loss: 0.6531 - val_accuracy: 0.6260\n",
            "Epoch 526/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6680 - val_loss: 0.6530 - val_accuracy: 0.6260\n",
            "Epoch 527/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6680 - val_loss: 0.6529 - val_accuracy: 0.6260\n",
            "Epoch 528/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6680 - val_loss: 0.6529 - val_accuracy: 0.6260\n",
            "Epoch 529/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6680 - val_loss: 0.6528 - val_accuracy: 0.6260\n",
            "Epoch 530/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6680 - val_loss: 0.6527 - val_accuracy: 0.6260\n",
            "Epoch 531/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6680 - val_loss: 0.6527 - val_accuracy: 0.6260\n",
            "Epoch 532/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6680 - val_loss: 0.6526 - val_accuracy: 0.6260\n",
            "Epoch 533/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6680 - val_loss: 0.6525 - val_accuracy: 0.6260\n",
            "Epoch 534/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6680 - val_loss: 0.6525 - val_accuracy: 0.6260\n",
            "Epoch 535/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6680 - val_loss: 0.6524 - val_accuracy: 0.6260\n",
            "Epoch 536/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6680 - val_loss: 0.6523 - val_accuracy: 0.6260\n",
            "Epoch 537/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6680 - val_loss: 0.6523 - val_accuracy: 0.6260\n",
            "Epoch 538/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6680 - val_loss: 0.6522 - val_accuracy: 0.6260\n",
            "Epoch 539/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6680 - val_loss: 0.6521 - val_accuracy: 0.6260\n",
            "Epoch 540/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6680 - val_loss: 0.6520 - val_accuracy: 0.6260\n",
            "Epoch 541/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6680 - val_loss: 0.6520 - val_accuracy: 0.6260\n",
            "Epoch 542/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6680 - val_loss: 0.6519 - val_accuracy: 0.6260\n",
            "Epoch 543/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6680 - val_loss: 0.6518 - val_accuracy: 0.6260\n",
            "Epoch 544/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.6680 - val_loss: 0.6518 - val_accuracy: 0.6260\n",
            "Epoch 545/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6680 - val_loss: 0.6517 - val_accuracy: 0.6260\n",
            "Epoch 546/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6680 - val_loss: 0.6516 - val_accuracy: 0.6260\n",
            "Epoch 547/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6680 - val_loss: 0.6516 - val_accuracy: 0.6260\n",
            "Epoch 548/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6680 - val_loss: 0.6515 - val_accuracy: 0.6260\n",
            "Epoch 549/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6680 - val_loss: 0.6514 - val_accuracy: 0.6260\n",
            "Epoch 550/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6680 - val_loss: 0.6513 - val_accuracy: 0.6260\n",
            "Epoch 551/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6680 - val_loss: 0.6513 - val_accuracy: 0.6260\n",
            "Epoch 552/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6680 - val_loss: 0.6512 - val_accuracy: 0.6260\n",
            "Epoch 553/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6680 - val_loss: 0.6511 - val_accuracy: 0.6260\n",
            "Epoch 554/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6680 - val_loss: 0.6511 - val_accuracy: 0.6260\n",
            "Epoch 555/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6680 - val_loss: 0.6510 - val_accuracy: 0.6260\n",
            "Epoch 556/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6680 - val_loss: 0.6509 - val_accuracy: 0.6260\n",
            "Epoch 557/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6680 - val_loss: 0.6508 - val_accuracy: 0.6260\n",
            "Epoch 558/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6680 - val_loss: 0.6508 - val_accuracy: 0.6260\n",
            "Epoch 559/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6680 - val_loss: 0.6507 - val_accuracy: 0.6260\n",
            "Epoch 560/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6680 - val_loss: 0.6506 - val_accuracy: 0.6260\n",
            "Epoch 561/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6680 - val_loss: 0.6506 - val_accuracy: 0.6260\n",
            "Epoch 562/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6680 - val_loss: 0.6505 - val_accuracy: 0.6260\n",
            "Epoch 563/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6680 - val_loss: 0.6504 - val_accuracy: 0.6260\n",
            "Epoch 564/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6680 - val_loss: 0.6503 - val_accuracy: 0.6260\n",
            "Epoch 565/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6680 - val_loss: 0.6503 - val_accuracy: 0.6260\n",
            "Epoch 566/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6680 - val_loss: 0.6502 - val_accuracy: 0.6260\n",
            "Epoch 567/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6680 - val_loss: 0.6501 - val_accuracy: 0.6260\n",
            "Epoch 568/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6680 - val_loss: 0.6500 - val_accuracy: 0.6260\n",
            "Epoch 569/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6680 - val_loss: 0.6500 - val_accuracy: 0.6260\n",
            "Epoch 570/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6680 - val_loss: 0.6499 - val_accuracy: 0.6260\n",
            "Epoch 571/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6680 - val_loss: 0.6498 - val_accuracy: 0.6260\n",
            "Epoch 572/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6680 - val_loss: 0.6497 - val_accuracy: 0.6260\n",
            "Epoch 573/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6680 - val_loss: 0.6497 - val_accuracy: 0.6260\n",
            "Epoch 574/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6680 - val_loss: 0.6496 - val_accuracy: 0.6260\n",
            "Epoch 575/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6680 - val_loss: 0.6495 - val_accuracy: 0.6260\n",
            "Epoch 576/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6680 - val_loss: 0.6495 - val_accuracy: 0.6260\n",
            "Epoch 577/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6680 - val_loss: 0.6494 - val_accuracy: 0.6260\n",
            "Epoch 578/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6680 - val_loss: 0.6493 - val_accuracy: 0.6260\n",
            "Epoch 579/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6680 - val_loss: 0.6492 - val_accuracy: 0.6260\n",
            "Epoch 580/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6680 - val_loss: 0.6492 - val_accuracy: 0.6260\n",
            "Epoch 581/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6680 - val_loss: 0.6491 - val_accuracy: 0.6260\n",
            "Epoch 582/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6680 - val_loss: 0.6490 - val_accuracy: 0.6260\n",
            "Epoch 583/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6680 - val_loss: 0.6489 - val_accuracy: 0.6260\n",
            "Epoch 584/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6680 - val_loss: 0.6489 - val_accuracy: 0.6260\n",
            "Epoch 585/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6680 - val_loss: 0.6488 - val_accuracy: 0.6260\n",
            "Epoch 586/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6680 - val_loss: 0.6487 - val_accuracy: 0.6260\n",
            "Epoch 587/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6680 - val_loss: 0.6486 - val_accuracy: 0.6260\n",
            "Epoch 588/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6680 - val_loss: 0.6486 - val_accuracy: 0.6260\n",
            "Epoch 589/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.6680 - val_loss: 0.6485 - val_accuracy: 0.6260\n",
            "Epoch 590/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6680 - val_loss: 0.6484 - val_accuracy: 0.6260\n",
            "Epoch 591/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.6680 - val_loss: 0.6484 - val_accuracy: 0.6260\n",
            "Epoch 592/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6680 - val_loss: 0.6483 - val_accuracy: 0.6260\n",
            "Epoch 593/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6680 - val_loss: 0.6482 - val_accuracy: 0.6260\n",
            "Epoch 594/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6680 - val_loss: 0.6482 - val_accuracy: 0.6260\n",
            "Epoch 595/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6680 - val_loss: 0.6481 - val_accuracy: 0.6260\n",
            "Epoch 596/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6680 - val_loss: 0.6480 - val_accuracy: 0.6260\n",
            "Epoch 597/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6680 - val_loss: 0.6480 - val_accuracy: 0.6260\n",
            "Epoch 598/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6680 - val_loss: 0.6479 - val_accuracy: 0.6260\n",
            "Epoch 599/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6680 - val_loss: 0.6478 - val_accuracy: 0.6260\n",
            "Epoch 600/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6680 - val_loss: 0.6477 - val_accuracy: 0.6260\n",
            "Epoch 601/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6680 - val_loss: 0.6477 - val_accuracy: 0.6260\n",
            "Epoch 602/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6680 - val_loss: 0.6476 - val_accuracy: 0.6260\n",
            "Epoch 603/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6680 - val_loss: 0.6475 - val_accuracy: 0.6260\n",
            "Epoch 604/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6680 - val_loss: 0.6474 - val_accuracy: 0.6260\n",
            "Epoch 605/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6680 - val_loss: 0.6474 - val_accuracy: 0.6260\n",
            "Epoch 606/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.6680 - val_loss: 0.6473 - val_accuracy: 0.6260\n",
            "Epoch 607/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6680 - val_loss: 0.6472 - val_accuracy: 0.6260\n",
            "Epoch 608/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6680 - val_loss: 0.6471 - val_accuracy: 0.6260\n",
            "Epoch 609/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6680 - val_loss: 0.6471 - val_accuracy: 0.6260\n",
            "Epoch 610/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6680 - val_loss: 0.6470 - val_accuracy: 0.6260\n",
            "Epoch 611/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6680 - val_loss: 0.6469 - val_accuracy: 0.6260\n",
            "Epoch 612/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6680 - val_loss: 0.6468 - val_accuracy: 0.6260\n",
            "Epoch 613/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6680 - val_loss: 0.6468 - val_accuracy: 0.6260\n",
            "Epoch 614/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6680 - val_loss: 0.6467 - val_accuracy: 0.6260\n",
            "Epoch 615/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.6680 - val_loss: 0.6466 - val_accuracy: 0.6260\n",
            "Epoch 616/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6680 - val_loss: 0.6466 - val_accuracy: 0.6260\n",
            "Epoch 617/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6680 - val_loss: 0.6465 - val_accuracy: 0.6260\n",
            "Epoch 618/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6680 - val_loss: 0.6464 - val_accuracy: 0.6260\n",
            "Epoch 619/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6680 - val_loss: 0.6463 - val_accuracy: 0.6260\n",
            "Epoch 620/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6680 - val_loss: 0.6463 - val_accuracy: 0.6260\n",
            "Epoch 621/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6680 - val_loss: 0.6462 - val_accuracy: 0.6260\n",
            "Epoch 622/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6680 - val_loss: 0.6461 - val_accuracy: 0.6260\n",
            "Epoch 623/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6680 - val_loss: 0.6460 - val_accuracy: 0.6260\n",
            "Epoch 624/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6680 - val_loss: 0.6460 - val_accuracy: 0.6260\n",
            "Epoch 625/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6680 - val_loss: 0.6459 - val_accuracy: 0.6260\n",
            "Epoch 626/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6680 - val_loss: 0.6458 - val_accuracy: 0.6260\n",
            "Epoch 627/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6680 - val_loss: 0.6457 - val_accuracy: 0.6260\n",
            "Epoch 628/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6680 - val_loss: 0.6457 - val_accuracy: 0.6260\n",
            "Epoch 629/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6680 - val_loss: 0.6456 - val_accuracy: 0.6260\n",
            "Epoch 630/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6680 - val_loss: 0.6455 - val_accuracy: 0.6260\n",
            "Epoch 631/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6680 - val_loss: 0.6454 - val_accuracy: 0.6260\n",
            "Epoch 632/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6680 - val_loss: 0.6453 - val_accuracy: 0.6260\n",
            "Epoch 633/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6680 - val_loss: 0.6453 - val_accuracy: 0.6260\n",
            "Epoch 634/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6680 - val_loss: 0.6452 - val_accuracy: 0.6260\n",
            "Epoch 635/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6680 - val_loss: 0.6451 - val_accuracy: 0.6260\n",
            "Epoch 636/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6680 - val_loss: 0.6450 - val_accuracy: 0.6260\n",
            "Epoch 637/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6680 - val_loss: 0.6450 - val_accuracy: 0.6260\n",
            "Epoch 638/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.6680 - val_loss: 0.6449 - val_accuracy: 0.6260\n",
            "Epoch 639/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6680 - val_loss: 0.6448 - val_accuracy: 0.6260\n",
            "Epoch 640/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6680 - val_loss: 0.6447 - val_accuracy: 0.6260\n",
            "Epoch 641/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6680 - val_loss: 0.6446 - val_accuracy: 0.6260\n",
            "Epoch 642/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6680 - val_loss: 0.6445 - val_accuracy: 0.6260\n",
            "Epoch 643/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6680 - val_loss: 0.6445 - val_accuracy: 0.6260\n",
            "Epoch 644/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6680 - val_loss: 0.6444 - val_accuracy: 0.6260\n",
            "Epoch 645/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6680 - val_loss: 0.6443 - val_accuracy: 0.6260\n",
            "Epoch 646/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6680 - val_loss: 0.6442 - val_accuracy: 0.6260\n",
            "Epoch 647/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6680 - val_loss: 0.6441 - val_accuracy: 0.6260\n",
            "Epoch 648/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6680 - val_loss: 0.6441 - val_accuracy: 0.6260\n",
            "Epoch 649/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6680 - val_loss: 0.6440 - val_accuracy: 0.6260\n",
            "Epoch 650/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6680 - val_loss: 0.6439 - val_accuracy: 0.6260\n",
            "Epoch 651/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6680 - val_loss: 0.6438 - val_accuracy: 0.6260\n",
            "Epoch 652/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6680 - val_loss: 0.6437 - val_accuracy: 0.6260\n",
            "Epoch 653/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6680 - val_loss: 0.6436 - val_accuracy: 0.6260\n",
            "Epoch 654/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6680 - val_loss: 0.6436 - val_accuracy: 0.6260\n",
            "Epoch 655/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6680 - val_loss: 0.6435 - val_accuracy: 0.6260\n",
            "Epoch 656/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.6680 - val_loss: 0.6434 - val_accuracy: 0.6260\n",
            "Epoch 657/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6680 - val_loss: 0.6433 - val_accuracy: 0.6260\n",
            "Epoch 658/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6680 - val_loss: 0.6432 - val_accuracy: 0.6260\n",
            "Epoch 659/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6680 - val_loss: 0.6431 - val_accuracy: 0.6260\n",
            "Epoch 660/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6680 - val_loss: 0.6430 - val_accuracy: 0.6260\n",
            "Epoch 661/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6680 - val_loss: 0.6430 - val_accuracy: 0.6260\n",
            "Epoch 662/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6680 - val_loss: 0.6429 - val_accuracy: 0.6260\n",
            "Epoch 663/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6680 - val_loss: 0.6428 - val_accuracy: 0.6260\n",
            "Epoch 664/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6680 - val_loss: 0.6427 - val_accuracy: 0.6260\n",
            "Epoch 665/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6680 - val_loss: 0.6426 - val_accuracy: 0.6260\n",
            "Epoch 666/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6680 - val_loss: 0.6425 - val_accuracy: 0.6260\n",
            "Epoch 667/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6680 - val_loss: 0.6424 - val_accuracy: 0.6260\n",
            "Epoch 668/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6680 - val_loss: 0.6423 - val_accuracy: 0.6260\n",
            "Epoch 669/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6680 - val_loss: 0.6422 - val_accuracy: 0.6260\n",
            "Epoch 670/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6680 - val_loss: 0.6421 - val_accuracy: 0.6260\n",
            "Epoch 671/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6680 - val_loss: 0.6421 - val_accuracy: 0.6260\n",
            "Epoch 672/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6680 - val_loss: 0.6420 - val_accuracy: 0.6260\n",
            "Epoch 673/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6680 - val_loss: 0.6419 - val_accuracy: 0.6260\n",
            "Epoch 674/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6680 - val_loss: 0.6418 - val_accuracy: 0.6260\n",
            "Epoch 675/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6680 - val_loss: 0.6417 - val_accuracy: 0.6260\n",
            "Epoch 676/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6680 - val_loss: 0.6416 - val_accuracy: 0.6260\n",
            "Epoch 677/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6680 - val_loss: 0.6415 - val_accuracy: 0.6260\n",
            "Epoch 678/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6680 - val_loss: 0.6414 - val_accuracy: 0.6260\n",
            "Epoch 679/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6680 - val_loss: 0.6414 - val_accuracy: 0.6260\n",
            "Epoch 680/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6680 - val_loss: 0.6413 - val_accuracy: 0.6260\n",
            "Epoch 681/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6680 - val_loss: 0.6412 - val_accuracy: 0.6260\n",
            "Epoch 682/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6680 - val_loss: 0.6411 - val_accuracy: 0.6260\n",
            "Epoch 683/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6680 - val_loss: 0.6410 - val_accuracy: 0.6260\n",
            "Epoch 684/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6680 - val_loss: 0.6409 - val_accuracy: 0.6260\n",
            "Epoch 685/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6680 - val_loss: 0.6408 - val_accuracy: 0.6260\n",
            "Epoch 686/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6680 - val_loss: 0.6408 - val_accuracy: 0.6260\n",
            "Epoch 687/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6680 - val_loss: 0.6407 - val_accuracy: 0.6260\n",
            "Epoch 688/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.6680 - val_loss: 0.6406 - val_accuracy: 0.6260\n",
            "Epoch 689/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.6680 - val_loss: 0.6405 - val_accuracy: 0.6260\n",
            "Epoch 690/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6680 - val_loss: 0.6404 - val_accuracy: 0.6260\n",
            "Epoch 691/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6680 - val_loss: 0.6403 - val_accuracy: 0.6260\n",
            "Epoch 692/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.6680 - val_loss: 0.6402 - val_accuracy: 0.6260\n",
            "Epoch 693/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6680 - val_loss: 0.6402 - val_accuracy: 0.6260\n",
            "Epoch 694/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6680 - val_loss: 0.6401 - val_accuracy: 0.6260\n",
            "Epoch 695/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6680 - val_loss: 0.6400 - val_accuracy: 0.6260\n",
            "Epoch 696/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6680 - val_loss: 0.6399 - val_accuracy: 0.6260\n",
            "Epoch 697/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6680 - val_loss: 0.6398 - val_accuracy: 0.6260\n",
            "Epoch 698/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6680 - val_loss: 0.6397 - val_accuracy: 0.6260\n",
            "Epoch 699/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6680 - val_loss: 0.6396 - val_accuracy: 0.6260\n",
            "Epoch 700/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.6680 - val_loss: 0.6395 - val_accuracy: 0.6260\n",
            "Epoch 701/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6680 - val_loss: 0.6394 - val_accuracy: 0.6260\n",
            "Epoch 702/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6680 - val_loss: 0.6394 - val_accuracy: 0.6260\n",
            "Epoch 703/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6680 - val_loss: 0.6393 - val_accuracy: 0.6260\n",
            "Epoch 704/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6680 - val_loss: 0.6392 - val_accuracy: 0.6260\n",
            "Epoch 705/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6680 - val_loss: 0.6391 - val_accuracy: 0.6260\n",
            "Epoch 706/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6680 - val_loss: 0.6390 - val_accuracy: 0.6260\n",
            "Epoch 707/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6680 - val_loss: 0.6389 - val_accuracy: 0.6260\n",
            "Epoch 708/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6680 - val_loss: 0.6389 - val_accuracy: 0.6260\n",
            "Epoch 709/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6680 - val_loss: 0.6388 - val_accuracy: 0.6260\n",
            "Epoch 710/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6680 - val_loss: 0.6387 - val_accuracy: 0.6260\n",
            "Epoch 711/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6680 - val_loss: 0.6386 - val_accuracy: 0.6260\n",
            "Epoch 712/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.6680 - val_loss: 0.6385 - val_accuracy: 0.6260\n",
            "Epoch 713/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6680 - val_loss: 0.6385 - val_accuracy: 0.6260\n",
            "Epoch 714/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6680 - val_loss: 0.6384 - val_accuracy: 0.6260\n",
            "Epoch 715/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6680 - val_loss: 0.6383 - val_accuracy: 0.6260\n",
            "Epoch 716/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6680 - val_loss: 0.6382 - val_accuracy: 0.6260\n",
            "Epoch 717/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6680 - val_loss: 0.6381 - val_accuracy: 0.6260\n",
            "Epoch 718/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6680 - val_loss: 0.6381 - val_accuracy: 0.6260\n",
            "Epoch 719/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6680 - val_loss: 0.6380 - val_accuracy: 0.6260\n",
            "Epoch 720/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.6680 - val_loss: 0.6379 - val_accuracy: 0.6260\n",
            "Epoch 721/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6680 - val_loss: 0.6378 - val_accuracy: 0.6260\n",
            "Epoch 722/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6680 - val_loss: 0.6378 - val_accuracy: 0.6260\n",
            "Epoch 723/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6680 - val_loss: 0.6377 - val_accuracy: 0.6260\n",
            "Epoch 724/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.6680 - val_loss: 0.6376 - val_accuracy: 0.6260\n",
            "Epoch 725/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6680 - val_loss: 0.6375 - val_accuracy: 0.6260\n",
            "Epoch 726/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6680 - val_loss: 0.6374 - val_accuracy: 0.6260\n",
            "Epoch 727/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6680 - val_loss: 0.6373 - val_accuracy: 0.6260\n",
            "Epoch 728/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.6680 - val_loss: 0.6373 - val_accuracy: 0.6260\n",
            "Epoch 729/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6680 - val_loss: 0.6372 - val_accuracy: 0.6260\n",
            "Epoch 730/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6680 - val_loss: 0.6371 - val_accuracy: 0.6260\n",
            "Epoch 731/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6680 - val_loss: 0.6370 - val_accuracy: 0.6260\n",
            "Epoch 732/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6680 - val_loss: 0.6369 - val_accuracy: 0.6260\n",
            "Epoch 733/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6680 - val_loss: 0.6369 - val_accuracy: 0.6260\n",
            "Epoch 734/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6680 - val_loss: 0.6368 - val_accuracy: 0.6260\n",
            "Epoch 735/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6680 - val_loss: 0.6367 - val_accuracy: 0.6260\n",
            "Epoch 736/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6680 - val_loss: 0.6366 - val_accuracy: 0.6260\n",
            "Epoch 737/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6680 - val_loss: 0.6365 - val_accuracy: 0.6260\n",
            "Epoch 738/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6680 - val_loss: 0.6365 - val_accuracy: 0.6260\n",
            "Epoch 739/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6680 - val_loss: 0.6364 - val_accuracy: 0.6260\n",
            "Epoch 740/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6680 - val_loss: 0.6363 - val_accuracy: 0.6260\n",
            "Epoch 741/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6680 - val_loss: 0.6362 - val_accuracy: 0.6260\n",
            "Epoch 742/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6680 - val_loss: 0.6361 - val_accuracy: 0.6260\n",
            "Epoch 743/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6680 - val_loss: 0.6360 - val_accuracy: 0.6260\n",
            "Epoch 744/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6680 - val_loss: 0.6360 - val_accuracy: 0.6260\n",
            "Epoch 745/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6680 - val_loss: 0.6359 - val_accuracy: 0.6260\n",
            "Epoch 746/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6680 - val_loss: 0.6358 - val_accuracy: 0.6260\n",
            "Epoch 747/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6680 - val_loss: 0.6357 - val_accuracy: 0.6260\n",
            "Epoch 748/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6680 - val_loss: 0.6357 - val_accuracy: 0.6260\n",
            "Epoch 749/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6680 - val_loss: 0.6356 - val_accuracy: 0.6260\n",
            "Epoch 750/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6680 - val_loss: 0.6355 - val_accuracy: 0.6260\n",
            "Epoch 751/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6680 - val_loss: 0.6354 - val_accuracy: 0.6260\n",
            "Epoch 752/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6680 - val_loss: 0.6353 - val_accuracy: 0.6260\n",
            "Epoch 753/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6680 - val_loss: 0.6352 - val_accuracy: 0.6260\n",
            "Epoch 754/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6680 - val_loss: 0.6352 - val_accuracy: 0.6260\n",
            "Epoch 755/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6680 - val_loss: 0.6351 - val_accuracy: 0.6260\n",
            "Epoch 756/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.6680 - val_loss: 0.6350 - val_accuracy: 0.6260\n",
            "Epoch 757/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6680 - val_loss: 0.6349 - val_accuracy: 0.6260\n",
            "Epoch 758/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.6680 - val_loss: 0.6348 - val_accuracy: 0.6260\n",
            "Epoch 759/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6680 - val_loss: 0.6348 - val_accuracy: 0.6260\n",
            "Epoch 760/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6680 - val_loss: 0.6347 - val_accuracy: 0.6260\n",
            "Epoch 761/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6680 - val_loss: 0.6346 - val_accuracy: 0.6260\n",
            "Epoch 762/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6680 - val_loss: 0.6345 - val_accuracy: 0.6260\n",
            "Epoch 763/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.6680 - val_loss: 0.6345 - val_accuracy: 0.6260\n",
            "Epoch 764/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6680 - val_loss: 0.6344 - val_accuracy: 0.6260\n",
            "Epoch 765/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6680 - val_loss: 0.6343 - val_accuracy: 0.6260\n",
            "Epoch 766/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6680 - val_loss: 0.6342 - val_accuracy: 0.6260\n",
            "Epoch 767/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.6680 - val_loss: 0.6341 - val_accuracy: 0.6260\n",
            "Epoch 768/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.6680 - val_loss: 0.6341 - val_accuracy: 0.6260\n",
            "Epoch 769/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.6680 - val_loss: 0.6340 - val_accuracy: 0.6260\n",
            "Epoch 770/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6680 - val_loss: 0.6339 - val_accuracy: 0.6260\n",
            "Epoch 771/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6680 - val_loss: 0.6338 - val_accuracy: 0.6260\n",
            "Epoch 772/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6680 - val_loss: 0.6337 - val_accuracy: 0.6260\n",
            "Epoch 773/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6680 - val_loss: 0.6337 - val_accuracy: 0.6260\n",
            "Epoch 774/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6680 - val_loss: 0.6336 - val_accuracy: 0.6260\n",
            "Epoch 775/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6680 - val_loss: 0.6335 - val_accuracy: 0.6260\n",
            "Epoch 776/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6680 - val_loss: 0.6334 - val_accuracy: 0.6260\n",
            "Epoch 777/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6680 - val_loss: 0.6334 - val_accuracy: 0.6260\n",
            "Epoch 778/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6680 - val_loss: 0.6333 - val_accuracy: 0.6260\n",
            "Epoch 779/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6680 - val_loss: 0.6332 - val_accuracy: 0.6260\n",
            "Epoch 780/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6680 - val_loss: 0.6331 - val_accuracy: 0.6260\n",
            "Epoch 781/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6680 - val_loss: 0.6330 - val_accuracy: 0.6260\n",
            "Epoch 782/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6680 - val_loss: 0.6330 - val_accuracy: 0.6260\n",
            "Epoch 783/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6680 - val_loss: 0.6329 - val_accuracy: 0.6260\n",
            "Epoch 784/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6680 - val_loss: 0.6328 - val_accuracy: 0.6260\n",
            "Epoch 785/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6680 - val_loss: 0.6327 - val_accuracy: 0.6260\n",
            "Epoch 786/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6680 - val_loss: 0.6326 - val_accuracy: 0.6260\n",
            "Epoch 787/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6680 - val_loss: 0.6326 - val_accuracy: 0.6260\n",
            "Epoch 788/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.6680 - val_loss: 0.6325 - val_accuracy: 0.6260\n",
            "Epoch 789/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.6680 - val_loss: 0.6324 - val_accuracy: 0.6260\n",
            "Epoch 790/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.6680 - val_loss: 0.6323 - val_accuracy: 0.6260\n",
            "Epoch 791/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6680 - val_loss: 0.6323 - val_accuracy: 0.6260\n",
            "Epoch 792/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6680 - val_loss: 0.6322 - val_accuracy: 0.6260\n",
            "Epoch 793/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6680 - val_loss: 0.6321 - val_accuracy: 0.6260\n",
            "Epoch 794/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6680 - val_loss: 0.6320 - val_accuracy: 0.6260\n",
            "Epoch 795/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6680 - val_loss: 0.6320 - val_accuracy: 0.6260\n",
            "Epoch 796/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6680 - val_loss: 0.6319 - val_accuracy: 0.6260\n",
            "Epoch 797/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6680 - val_loss: 0.6318 - val_accuracy: 0.6260\n",
            "Epoch 798/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.6680 - val_loss: 0.6318 - val_accuracy: 0.6260\n",
            "Epoch 799/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6680 - val_loss: 0.6317 - val_accuracy: 0.6260\n",
            "Epoch 800/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.6680 - val_loss: 0.6316 - val_accuracy: 0.6260\n",
            "Epoch 801/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6680 - val_loss: 0.6315 - val_accuracy: 0.6260\n",
            "Epoch 802/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6680 - val_loss: 0.6315 - val_accuracy: 0.6260\n",
            "Epoch 803/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6680 - val_loss: 0.6314 - val_accuracy: 0.6260\n",
            "Epoch 804/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6680 - val_loss: 0.6313 - val_accuracy: 0.6260\n",
            "Epoch 805/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6680 - val_loss: 0.6312 - val_accuracy: 0.6260\n",
            "Epoch 806/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6680 - val_loss: 0.6312 - val_accuracy: 0.6260\n",
            "Epoch 807/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.6680 - val_loss: 0.6311 - val_accuracy: 0.6260\n",
            "Epoch 808/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6680 - val_loss: 0.6310 - val_accuracy: 0.6260\n",
            "Epoch 809/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.6680 - val_loss: 0.6309 - val_accuracy: 0.6260\n",
            "Epoch 810/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6680 - val_loss: 0.6309 - val_accuracy: 0.6260\n",
            "Epoch 811/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6680 - val_loss: 0.6308 - val_accuracy: 0.6260\n",
            "Epoch 812/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6680 - val_loss: 0.6307 - val_accuracy: 0.6260\n",
            "Epoch 813/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6680 - val_loss: 0.6307 - val_accuracy: 0.6260\n",
            "Epoch 814/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6680 - val_loss: 0.6306 - val_accuracy: 0.6260\n",
            "Epoch 815/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6680 - val_loss: 0.6305 - val_accuracy: 0.6260\n",
            "Epoch 816/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.6680 - val_loss: 0.6305 - val_accuracy: 0.6260\n",
            "Epoch 817/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6680 - val_loss: 0.6304 - val_accuracy: 0.6260\n",
            "Epoch 818/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6680 - val_loss: 0.6303 - val_accuracy: 0.6260\n",
            "Epoch 819/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6680 - val_loss: 0.6302 - val_accuracy: 0.6260\n",
            "Epoch 820/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6680 - val_loss: 0.6302 - val_accuracy: 0.6260\n",
            "Epoch 821/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6680 - val_loss: 0.6301 - val_accuracy: 0.6260\n",
            "Epoch 822/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6680 - val_loss: 0.6300 - val_accuracy: 0.6260\n",
            "Epoch 823/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6680 - val_loss: 0.6299 - val_accuracy: 0.6260\n",
            "Epoch 824/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6680 - val_loss: 0.6299 - val_accuracy: 0.6260\n",
            "Epoch 825/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6680 - val_loss: 0.6298 - val_accuracy: 0.6260\n",
            "Epoch 826/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.6680 - val_loss: 0.6297 - val_accuracy: 0.6260\n",
            "Epoch 827/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6680 - val_loss: 0.6296 - val_accuracy: 0.6260\n",
            "Epoch 828/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6680 - val_loss: 0.6296 - val_accuracy: 0.6260\n",
            "Epoch 829/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6680 - val_loss: 0.6295 - val_accuracy: 0.6260\n",
            "Epoch 830/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6680 - val_loss: 0.6294 - val_accuracy: 0.6260\n",
            "Epoch 831/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6680 - val_loss: 0.6293 - val_accuracy: 0.6260\n",
            "Epoch 832/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6680 - val_loss: 0.6293 - val_accuracy: 0.6260\n",
            "Epoch 833/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6680 - val_loss: 0.6292 - val_accuracy: 0.6260\n",
            "Epoch 834/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6680 - val_loss: 0.6291 - val_accuracy: 0.6260\n",
            "Epoch 835/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6680 - val_loss: 0.6290 - val_accuracy: 0.6260\n",
            "Epoch 836/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6680 - val_loss: 0.6290 - val_accuracy: 0.6260\n",
            "Epoch 837/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.6680 - val_loss: 0.6289 - val_accuracy: 0.6260\n",
            "Epoch 838/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6680 - val_loss: 0.6288 - val_accuracy: 0.6260\n",
            "Epoch 839/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.6680 - val_loss: 0.6287 - val_accuracy: 0.6260\n",
            "Epoch 840/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.6680 - val_loss: 0.6286 - val_accuracy: 0.6260\n",
            "Epoch 841/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6680 - val_loss: 0.6286 - val_accuracy: 0.6260\n",
            "Epoch 842/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6680 - val_loss: 0.6285 - val_accuracy: 0.6260\n",
            "Epoch 843/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6680 - val_loss: 0.6284 - val_accuracy: 0.6260\n",
            "Epoch 844/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6680 - val_loss: 0.6283 - val_accuracy: 0.6260\n",
            "Epoch 845/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.6680 - val_loss: 0.6283 - val_accuracy: 0.6260\n",
            "Epoch 846/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6680 - val_loss: 0.6282 - val_accuracy: 0.6260\n",
            "Epoch 847/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6680 - val_loss: 0.6281 - val_accuracy: 0.6260\n",
            "Epoch 848/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6680 - val_loss: 0.6280 - val_accuracy: 0.6260\n",
            "Epoch 849/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6680 - val_loss: 0.6279 - val_accuracy: 0.6260\n",
            "Epoch 850/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6680 - val_loss: 0.6279 - val_accuracy: 0.6260\n",
            "Epoch 851/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.6680 - val_loss: 0.6278 - val_accuracy: 0.6260\n",
            "Epoch 852/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.6680 - val_loss: 0.6277 - val_accuracy: 0.6260\n",
            "Epoch 853/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6680 - val_loss: 0.6276 - val_accuracy: 0.6260\n",
            "Epoch 854/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6680 - val_loss: 0.6276 - val_accuracy: 0.6260\n",
            "Epoch 855/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6680 - val_loss: 0.6275 - val_accuracy: 0.6260\n",
            "Epoch 856/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6680 - val_loss: 0.6274 - val_accuracy: 0.6260\n",
            "Epoch 857/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6680 - val_loss: 0.6273 - val_accuracy: 0.6260\n",
            "Epoch 858/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6680 - val_loss: 0.6272 - val_accuracy: 0.6260\n",
            "Epoch 859/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6680 - val_loss: 0.6272 - val_accuracy: 0.6260\n",
            "Epoch 860/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.6680 - val_loss: 0.6271 - val_accuracy: 0.6341\n",
            "Epoch 861/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6680 - val_loss: 0.6270 - val_accuracy: 0.6341\n",
            "Epoch 862/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6680 - val_loss: 0.6269 - val_accuracy: 0.6341\n",
            "Epoch 863/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6680 - val_loss: 0.6268 - val_accuracy: 0.6341\n",
            "Epoch 864/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.6680 - val_loss: 0.6267 - val_accuracy: 0.6341\n",
            "Epoch 865/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.6680 - val_loss: 0.6267 - val_accuracy: 0.6341\n",
            "Epoch 866/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6680 - val_loss: 0.6266 - val_accuracy: 0.6341\n",
            "Epoch 867/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6680 - val_loss: 0.6265 - val_accuracy: 0.6341\n",
            "Epoch 868/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.6680 - val_loss: 0.6264 - val_accuracy: 0.6341\n",
            "Epoch 869/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6680 - val_loss: 0.6264 - val_accuracy: 0.6341\n",
            "Epoch 870/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6680 - val_loss: 0.6263 - val_accuracy: 0.6341\n",
            "Epoch 871/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6680 - val_loss: 0.6262 - val_accuracy: 0.6341\n",
            "Epoch 872/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.6680 - val_loss: 0.6261 - val_accuracy: 0.6341\n",
            "Epoch 873/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6680 - val_loss: 0.6260 - val_accuracy: 0.6341\n",
            "Epoch 874/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6680 - val_loss: 0.6260 - val_accuracy: 0.6341\n",
            "Epoch 875/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.6680 - val_loss: 0.6259 - val_accuracy: 0.6341\n",
            "Epoch 876/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6680 - val_loss: 0.6258 - val_accuracy: 0.6341\n",
            "Epoch 877/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6680 - val_loss: 0.6257 - val_accuracy: 0.6341\n",
            "Epoch 878/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6680 - val_loss: 0.6256 - val_accuracy: 0.6341\n",
            "Epoch 879/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6680 - val_loss: 0.6255 - val_accuracy: 0.6341\n",
            "Epoch 880/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6680 - val_loss: 0.6255 - val_accuracy: 0.6341\n",
            "Epoch 881/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.6680 - val_loss: 0.6254 - val_accuracy: 0.6341\n",
            "Epoch 882/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6680 - val_loss: 0.6253 - val_accuracy: 0.6341\n",
            "Epoch 883/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.6680 - val_loss: 0.6252 - val_accuracy: 0.6341\n",
            "Epoch 884/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6680 - val_loss: 0.6252 - val_accuracy: 0.6341\n",
            "Epoch 885/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.6680 - val_loss: 0.6251 - val_accuracy: 0.6341\n",
            "Epoch 886/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.6680 - val_loss: 0.6250 - val_accuracy: 0.6341\n",
            "Epoch 887/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.6680 - val_loss: 0.6249 - val_accuracy: 0.6341\n",
            "Epoch 888/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.6680 - val_loss: 0.6248 - val_accuracy: 0.6341\n",
            "Epoch 889/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.6680 - val_loss: 0.6248 - val_accuracy: 0.6341\n",
            "Epoch 890/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.6680 - val_loss: 0.6247 - val_accuracy: 0.6341\n",
            "Epoch 891/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6680 - val_loss: 0.6246 - val_accuracy: 0.6341\n",
            "Epoch 892/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6680 - val_loss: 0.6245 - val_accuracy: 0.6341\n",
            "Epoch 893/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6680 - val_loss: 0.6244 - val_accuracy: 0.6341\n",
            "Epoch 894/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6680 - val_loss: 0.6244 - val_accuracy: 0.6341\n",
            "Epoch 895/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.6680 - val_loss: 0.6243 - val_accuracy: 0.6341\n",
            "Epoch 896/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6680 - val_loss: 0.6242 - val_accuracy: 0.6341\n",
            "Epoch 897/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6680 - val_loss: 0.6241 - val_accuracy: 0.6341\n",
            "Epoch 898/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6680 - val_loss: 0.6241 - val_accuracy: 0.6341\n",
            "Epoch 899/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.6701 - val_loss: 0.6240 - val_accuracy: 0.6341\n",
            "Epoch 900/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6701 - val_loss: 0.6239 - val_accuracy: 0.6341\n",
            "Epoch 901/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6701 - val_loss: 0.6238 - val_accuracy: 0.6423\n",
            "Epoch 902/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.6701 - val_loss: 0.6237 - val_accuracy: 0.6423\n",
            "Epoch 903/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.6701 - val_loss: 0.6237 - val_accuracy: 0.6423\n",
            "Epoch 904/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6701 - val_loss: 0.6236 - val_accuracy: 0.6423\n",
            "Epoch 905/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6701 - val_loss: 0.6235 - val_accuracy: 0.6504\n",
            "Epoch 906/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6701 - val_loss: 0.6234 - val_accuracy: 0.6504\n",
            "Epoch 907/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.6701 - val_loss: 0.6233 - val_accuracy: 0.6504\n",
            "Epoch 908/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6701 - val_loss: 0.6233 - val_accuracy: 0.6504\n",
            "Epoch 909/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6701 - val_loss: 0.6232 - val_accuracy: 0.6504\n",
            "Epoch 910/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.6701 - val_loss: 0.6231 - val_accuracy: 0.6504\n",
            "Epoch 911/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6701 - val_loss: 0.6230 - val_accuracy: 0.6504\n",
            "Epoch 912/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6701 - val_loss: 0.6229 - val_accuracy: 0.6504\n",
            "Epoch 913/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6701 - val_loss: 0.6229 - val_accuracy: 0.6504\n",
            "Epoch 914/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6701 - val_loss: 0.6228 - val_accuracy: 0.6504\n",
            "Epoch 915/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6701 - val_loss: 0.6227 - val_accuracy: 0.6504\n",
            "Epoch 916/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6701 - val_loss: 0.6226 - val_accuracy: 0.6504\n",
            "Epoch 917/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6701 - val_loss: 0.6225 - val_accuracy: 0.6504\n",
            "Epoch 918/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.6701 - val_loss: 0.6225 - val_accuracy: 0.6504\n",
            "Epoch 919/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6680 - val_loss: 0.6224 - val_accuracy: 0.6504\n",
            "Epoch 920/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6680 - val_loss: 0.6223 - val_accuracy: 0.6423\n",
            "Epoch 921/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.6680 - val_loss: 0.6222 - val_accuracy: 0.6423\n",
            "Epoch 922/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.6680 - val_loss: 0.6221 - val_accuracy: 0.6423\n",
            "Epoch 923/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6680 - val_loss: 0.6221 - val_accuracy: 0.6423\n",
            "Epoch 924/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6680 - val_loss: 0.6220 - val_accuracy: 0.6423\n",
            "Epoch 925/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.6680 - val_loss: 0.6219 - val_accuracy: 0.6423\n",
            "Epoch 926/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6680 - val_loss: 0.6218 - val_accuracy: 0.6423\n",
            "Epoch 927/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6680 - val_loss: 0.6217 - val_accuracy: 0.6423\n",
            "Epoch 928/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6680 - val_loss: 0.6217 - val_accuracy: 0.6423\n",
            "Epoch 929/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6680 - val_loss: 0.6216 - val_accuracy: 0.6423\n",
            "Epoch 930/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6680 - val_loss: 0.6215 - val_accuracy: 0.6423\n",
            "Epoch 931/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6701 - val_loss: 0.6214 - val_accuracy: 0.6423\n",
            "Epoch 932/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6680 - val_loss: 0.6214 - val_accuracy: 0.6423\n",
            "Epoch 933/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.6701 - val_loss: 0.6213 - val_accuracy: 0.6423\n",
            "Epoch 934/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6701 - val_loss: 0.6212 - val_accuracy: 0.6504\n",
            "Epoch 935/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6701 - val_loss: 0.6211 - val_accuracy: 0.6504\n",
            "Epoch 936/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6701 - val_loss: 0.6210 - val_accuracy: 0.6504\n",
            "Epoch 937/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6701 - val_loss: 0.6209 - val_accuracy: 0.6504\n",
            "Epoch 938/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6701 - val_loss: 0.6209 - val_accuracy: 0.6504\n",
            "Epoch 939/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6701 - val_loss: 0.6208 - val_accuracy: 0.6504\n",
            "Epoch 940/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6701 - val_loss: 0.6207 - val_accuracy: 0.6504\n",
            "Epoch 941/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6701 - val_loss: 0.6206 - val_accuracy: 0.6504\n",
            "Epoch 942/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6701 - val_loss: 0.6206 - val_accuracy: 0.6504\n",
            "Epoch 943/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.6680 - val_loss: 0.6205 - val_accuracy: 0.6504\n",
            "Epoch 944/1000\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6680 - val_loss: 0.6204 - val_accuracy: 0.6504\n",
            "Epoch 945/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6680 - val_loss: 0.6203 - val_accuracy: 0.6504\n",
            "Epoch 946/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6680 - val_loss: 0.6202 - val_accuracy: 0.6504\n",
            "Epoch 947/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6680 - val_loss: 0.6202 - val_accuracy: 0.6504\n",
            "Epoch 948/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.6680 - val_loss: 0.6201 - val_accuracy: 0.6504\n",
            "Epoch 949/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.6680 - val_loss: 0.6200 - val_accuracy: 0.6504\n",
            "Epoch 950/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6680 - val_loss: 0.6199 - val_accuracy: 0.6504\n",
            "Epoch 951/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6680 - val_loss: 0.6198 - val_accuracy: 0.6504\n",
            "Epoch 952/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.6680 - val_loss: 0.6197 - val_accuracy: 0.6504\n",
            "Epoch 953/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6680 - val_loss: 0.6197 - val_accuracy: 0.6504\n",
            "Epoch 954/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.6680 - val_loss: 0.6196 - val_accuracy: 0.6504\n",
            "Epoch 955/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6680 - val_loss: 0.6195 - val_accuracy: 0.6504\n",
            "Epoch 956/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.6680 - val_loss: 0.6194 - val_accuracy: 0.6504\n",
            "Epoch 957/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6680 - val_loss: 0.6193 - val_accuracy: 0.6504\n",
            "Epoch 958/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6680 - val_loss: 0.6192 - val_accuracy: 0.6504\n",
            "Epoch 959/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6680 - val_loss: 0.6192 - val_accuracy: 0.6504\n",
            "Epoch 960/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6680 - val_loss: 0.6191 - val_accuracy: 0.6504\n",
            "Epoch 961/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6701 - val_loss: 0.6190 - val_accuracy: 0.6504\n",
            "Epoch 962/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6701 - val_loss: 0.6189 - val_accuracy: 0.6504\n",
            "Epoch 963/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6701 - val_loss: 0.6188 - val_accuracy: 0.6504\n",
            "Epoch 964/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.6701 - val_loss: 0.6187 - val_accuracy: 0.6504\n",
            "Epoch 965/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.6701 - val_loss: 0.6187 - val_accuracy: 0.6504\n",
            "Epoch 966/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6701 - val_loss: 0.6186 - val_accuracy: 0.6504\n",
            "Epoch 967/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6680 - val_loss: 0.6185 - val_accuracy: 0.6504\n",
            "Epoch 968/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6680 - val_loss: 0.6184 - val_accuracy: 0.6504\n",
            "Epoch 969/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.6680 - val_loss: 0.6183 - val_accuracy: 0.6504\n",
            "Epoch 970/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.6680 - val_loss: 0.6182 - val_accuracy: 0.6504\n",
            "Epoch 971/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6680 - val_loss: 0.6182 - val_accuracy: 0.6504\n",
            "Epoch 972/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6680 - val_loss: 0.6181 - val_accuracy: 0.6504\n",
            "Epoch 973/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.6680 - val_loss: 0.6180 - val_accuracy: 0.6504\n",
            "Epoch 974/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6680 - val_loss: 0.6179 - val_accuracy: 0.6504\n",
            "Epoch 975/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6680 - val_loss: 0.6178 - val_accuracy: 0.6504\n",
            "Epoch 976/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6680 - val_loss: 0.6177 - val_accuracy: 0.6504\n",
            "Epoch 977/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6701 - val_loss: 0.6177 - val_accuracy: 0.6504\n",
            "Epoch 978/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.6701 - val_loss: 0.6176 - val_accuracy: 0.6504\n",
            "Epoch 979/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6701 - val_loss: 0.6175 - val_accuracy: 0.6504\n",
            "Epoch 980/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6701 - val_loss: 0.6174 - val_accuracy: 0.6585\n",
            "Epoch 981/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6701 - val_loss: 0.6173 - val_accuracy: 0.6585\n",
            "Epoch 982/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6701 - val_loss: 0.6173 - val_accuracy: 0.6585\n",
            "Epoch 983/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.6701 - val_loss: 0.6172 - val_accuracy: 0.6585\n",
            "Epoch 984/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.6701 - val_loss: 0.6171 - val_accuracy: 0.6585\n",
            "Epoch 985/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6721 - val_loss: 0.6170 - val_accuracy: 0.6585\n",
            "Epoch 986/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6721 - val_loss: 0.6169 - val_accuracy: 0.6585\n",
            "Epoch 987/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6721 - val_loss: 0.6168 - val_accuracy: 0.6585\n",
            "Epoch 988/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6721 - val_loss: 0.6167 - val_accuracy: 0.6585\n",
            "Epoch 989/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6701 - val_loss: 0.6167 - val_accuracy: 0.6585\n",
            "Epoch 990/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6701 - val_loss: 0.6166 - val_accuracy: 0.6585\n",
            "Epoch 991/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6701 - val_loss: 0.6165 - val_accuracy: 0.6585\n",
            "Epoch 992/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.6701 - val_loss: 0.6164 - val_accuracy: 0.6585\n",
            "Epoch 993/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.6701 - val_loss: 0.6163 - val_accuracy: 0.6585\n",
            "Epoch 994/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6701 - val_loss: 0.6162 - val_accuracy: 0.6585\n",
            "Epoch 995/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.6701 - val_loss: 0.6162 - val_accuracy: 0.6585\n",
            "Epoch 996/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.6701 - val_loss: 0.6161 - val_accuracy: 0.6585\n",
            "Epoch 997/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.6701 - val_loss: 0.6160 - val_accuracy: 0.6585\n",
            "Epoch 998/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6701 - val_loss: 0.6159 - val_accuracy: 0.6585\n",
            "Epoch 999/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.6701 - val_loss: 0.6158 - val_accuracy: 0.6585\n",
            "Epoch 1000/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6680 - val_loss: 0.6158 - val_accuracy: 0.6585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "79e303f3-c055-4416-8604-9a736ace6511"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "67ed5287-8d2f-47a8-e36f-95e76a00b094"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "2dca13f0-67ae-4e8c-b293-74a69c97c082"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60493016, 0.39506984]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "e6091de4-d989-4885-8d15-6209fb40b6f5"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}